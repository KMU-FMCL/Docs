{"Language/C++/C++-Structure":{"title":"Structure","links":[],"tags":["CPP"],"content":"Structure\n\nC++ 언어에서는 구조체의 태그(tag)가 곧 자료형\n\n\n\n                  \n                  Example\n                  \n                \n\n#include &lt;iostream&gt;\nusing namespace std;\n \nstruct Score {\n          char  name[12];\n          int   kor, eng, math, tat;\n          flot  ave;\n};\n \nint main()\n{\n          // Struct Score   temp;       // C Language Style\n          Score             temp;       // C++ Language Style\n \n          return 0;\n}\n\n\n\n\n                  \n                  구조체 &amp; 공용체 \n                  \n                \n\n\n\n                  \n                  Big endian &amp; Little endian \n                  \n                \n\n#include &lt;iostream&gt;\nusing namespace std;\n \n// 비트 필드 구조체 형식 정의\nstruct Unit {\n        unsigned int  FirstBit : 8;\n        unsigned int  SecondBit : 8;\n        unsigned int  ThirdBit : 8;\n        unsigned int  ForthBit : 8;\n};\n \n// 공용체 형식 정의: 정수형과 구조체 멤버\nunion Endian {\n        int     a;      // 정수형 멤버\n        Uint    b;      // 구조체 멤버\n};\n \nint main()\n{\n      // 공용체 변수 선언\n      Endian          temp;\n      temp.a = 0x12345678;\n \n      // &quot;Big endian&quot; &amp; &quot;Little endian&quot;\n      cout &lt;&lt; hex;\n      cout &lt;&lt; &quot;temp.i: &quot; &lt;&lt; temp.a &lt;&lt; endl;             // x12345678\n      cout &lt;&lt; &quot;temp.i: &quot; &lt;&lt; temp.b.FirstBit &lt;&lt; endl;    // 78\n      cout &lt;&lt; &quot;temp.i: &quot; &lt;&lt; temp.b.SecondBit &lt;&lt; endl;   // 56\n      cout &lt;&lt; &quot;temp.i: &quot; &lt;&lt; temp.b.ThirdBit &lt;&lt; endl;    // 34\n      cout &lt;&lt; &quot;temp.i: &quot; &lt;&lt; temp.b.ForthBit &lt;&lt; endl;    // 12\n \n      return 0;\n}\n\n\n\n\n                  \n                  TV 채널 \n                  \n                \n\n#include &lt;iostream&gt;\nusing namespace std;\n \nint main()\n{\n        // 열거형 정의\n        enum TV {\n                afn = 2, sbs = 6, kbs2 = 7,\n                kbs1 = 9, mbc = 11, ebs = 13,\n                ytn = 60, mbn = 61, cnn = 51\n        };\n \n        cout &lt;&lt; &quot;즐겨보는 TV 채널 목록&quot; &lt;&lt; endl;\n        cout &lt;&lt; &quot;   AFN : &quot; &lt;&lt; afn &lt;&lt; endl;\n        cout &lt;&lt; &quot;   SBS : &quot; &lt;&lt; sbs &lt;&lt; endl;\n        cout &lt;&lt; &quot;   KBS2: &quot; &lt;&lt; kbs2 &lt;&lt; endl;\n        cout &lt;&lt; &quot;   KBS1: &quot; &lt;&lt; kbs1 &lt;&lt; endl;\n        cout &lt;&lt; &quot;   MBC : &quot; &lt;&lt; mbc &lt;&lt; endl;\n        cout &lt;&lt; &quot;   EBS : &quot; &lt;&lt; ebs &lt;&lt; endl;\n        cout &lt;&lt; &quot;   YTN : &quot; &lt;&lt; ytn &lt;&lt; endl;\n        cout &lt;&lt; &quot;   CNN : &quot; &lt;&lt; cnn &lt;&lt; endl;\n \n        return 0;\n}\n\n\n\n"},"Language/C++/C++":{"title":"C++","links":[],"tags":["Language","CPP"],"content":"C++\n구조체와 객체"},"Language/C/C":{"title":"C","links":[],"tags":["Language","C"],"content":"C"},"Language/Go/Go":{"title":"Go","links":[],"tags":["Language","Go"],"content":""},"Language/Python/FastAPI/FastAPI-Application":{"title":"Application","links":["Web/JSON--and--API-Data-Type","Language/Python/FastAPI/FastAPI","Web/Concurrency","Web/REST","Language/Python/Python","Language/Python/Python-Variable","Web/HTTP"],"tags":["Python/FastAPI"],"content":"Application\nDefault Python Package\n\n\n                  \n                  Package \n                  \n                \n\n\n\n                  \n                  FastAPI \n                  \n                \n\n\nWeb Framework\n\npip install fastapi\n\n\n\n\n                  \n                   Uvicorn\n                  \n                \n\n\nAsynchronous Web Server\n\npip install uvicorn\n\n\n\n\n                  \n                   HTTPie\n                  \n                \n\n\nText Web Client\n가장 잘 알려진 Text Web CLient 는 curl\n\nBut, HTTPie 가 더 사용하기 쉽고 기본적으로 JSON Encoding/Decoding 을 사용하므로 FastAPI 와 더 잘 어울림\n\n\n\npip install httpie\n\n\n\n\n                  \n                   Requests Synchronous\n                  \n                \n\n\nSynchronous Web Client Package\n\npip install requests\n\n\n\n\n                  \n                   HTTPX Synchronous &amp; Asynchronous\n                  \n                \n\n\nAsynchronous/Synchronous Web Client Package\n\npip install httpx\n\n\n\n\nExample\n\n\n                  \n                   Endpoint:hello.py\n                  \n                \n\nfrom fastapi import FastAPI\n \napp = FastAPI()\n \n@app.get(&quot;/hi&quot;)\ndef greet():\n    return &quot;Hello? World?&quot;\n\n\n\n\n                  \n                   Uvicorn\n                  \n                \n\n\n\n                  \n                  Command Line \n                  \n                \n\nuvicorn hello:app --reload\n\n\n\n\n                  \n                  Internally \n                  \n                \n\nfrom fastapi import FastAPI\n \napp = FastAPI()\n \n@app.get(&quot;/hi&quot;)\ndef greet():\n    return &quot;Hello? World?&quot;\n \nif __name__ == &quot;__main__&quot;:\n    import uvicorn\n    uvicorn.run(&quot;hello:app&quot;, reload=True)\n\n\n어느 경우든,  reload Argument 는 hello.py 가 변경되면 Web Server 를 다시 시작하도록 Uvicorn 에 지시\n\n두 경우 기본적으로 localhost 의 8000 번 Port 를 사용\n\n외부 &amp; 내부,  어디에서 시작하든 두 경우 모두 원하는 host &amp; port Argument 사용 가능\n\n\n\n\n\n\n\n                  \n                  Test \n                  \n                \n\n이제 Server 에 단일 Endpoint(/hi)가 있고 Request 를 받을 준비 완료\n\n\nBrowser: 상단 주소창에 URL 입력\n\n\nHTTPie: 표시된 Command 입력\n\n\nRequest &amp; HTTPX: Python Interpreter 사용해서 입력\n\n\n\n\n                  \n                  Browser \n                  \n                \n\n\nhttp://localhost:8000/hi\n\n\n\n\n\n                  \n                   Requests\n                  \n                \n\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; r = requests.get(&quot;http://localhost:8000/hi&quot;)\n&gt;&gt;&gt; r.json()\n\n\n\n\n                  \n                   HTTPX\n                  \n                \n\n&gt;&gt;&gt; import httpx\n&gt;&gt;&gt; r = httpx.get(&quot;http://localhost:8000/hi&quot;)\n&gt;&gt;&gt; r.json()\n\n\n\n\n                  \n                   HTTPie\n                  \n                \n\n\n\n                  \n                  Basic \n                  \n                \n\nhttp localhost:8000/hi\n\n\n\n\n                  \n                  Response Body \n                  \n                \n\nhttp -b localhost:8000/hi\n\n\n\n\n-b 를 사용해 Response Header 를 건너뛰고 Body 만 Print\n\n\n\n\n                  \n                  Display All Information \n                  \n                \n\nhttp -v localhost:8000/hi\n\n\n\n-v 를 사용해 Full Request Header &amp; Response 를 가져옴.\n\n\n\n\n\nCaution\n\napp 은 All Web Application 을 나타내는 최상위 FastAPI Object\n\n\n\napp.get(&quot;/hi&quot;) 는 Path Decorator. 이는 FastAPI 에 다음 사항을 알려줌.\n\nURL “/hi” 에 대한 Request 는 Next Function 으로 전달돼야 함.\nDecorator 는 HTTP GET 동사에만 적용.\n\n또한 다른 HTTP 동사(PUT, POST, etc.)와 함께 전송된 “/hi” URL 에 응답할 수 있는데, 각 동사에는 개별 기능이 있음.\n\n\n\n\n\n\n\ndef greet()1 은 Path Function 으로,  HTTP Request &amp; Response 의 주요 접점.\n\n\n\nFastAPI 를 Test 하는데 Requests &amp; HTTPX 중 어느 것이 좋다고 단언할 수 없음.\n\n앞으로의 Example 에서는 Requests 를 사용하나 Asynchronous Request 를 할 때는 HTTPX 를 사용\n\n\n\n\nFootnotes\n\n  현재 에시엔 Argument 가 없지만,  FastAPI 내부에 훨씬 더 많은 기능이 존재함.\n    ↩\n  \n"},"Language/Python/FastAPI/FastAPI-Body":{"title":"Body","links":["Language/Python/FastAPI/FastAPI-URL-Path","Language/Python/FastAPI/FastAPI-Query-Parameter","Web/REST","Language/Python/FastAPI/FastAPI","Web/JSON--and--API-Data-Type"],"tags":["Python/FastAPI"],"content":"Body\nGET\n\n멱등성(idempotent)1 을 가져야 하며,  Result 만 Return 해야 함.\n\nRequest\n\n  Path &amp; Query Parameter 는  사용 가능\n  Request Body 는 사용 불가능\n\nRequest Body\n\n주로 POST,   PUT &amp; PATCH Request 에서 Server 로 Info 를 전달할 때 사용\n\nExample\n\n\n                  \n                  Body \n                  \n                \n\n\n\nEndpoint 를 GET 에서 POST 로 Change\n\n\n\n\n                  \n                  Return String Body \n                  \n                \n\nfrom fastapi import FastAPI, Body\n \napp = FastAPI()\n \n@app.post(&quot;/hi&quot;)\ndef greet(who: str = Body(embed=True)):\n    return f&quot;Hello? {who}?&quot;\n\n\n\n\n                  \n                  Caution\n                  \n                \n\n\nFastAPI 에서 POST Request 로 Body 를 받으려면 Function Parameter 에 Body(embed=True) 사용\nClient 에서 Request Body 를 보낼 때는 JSON Type 으로 Data 전송\n\nEmbed 부분은 단순히 “String” 이 아니라 {&quot;key&quot;: &quot;Value&quot;} 처럼 보여야 함\n\n\n\n\n\n\n\n\n\n                  \n                  Test \n                  \n                \n\n\n\nArgument json 을 사용해 Request Body 에 JSON Encoding 한 Data 전달(POST Request)\n\n\n\n\n                  \n                  HTTPie \n                  \n                \n\nhttp -v localhost:8000/hi who=Mom\n\n\n\n\n                  \n                  Requests \n                  \n                \n\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; r = requests.post(&quot;http://localhost:8000/hi&quot;, json={&quot;who&quot;, &quot;Mom&quot;})\n&gt;&gt;&gt; r.json()\n\n\n\n\nFootnotes\n\n\n같은 질문엔 같은 답을 얻는다는 뜻 ↩\n\n\n"},"Language/Python/FastAPI/FastAPI-HTTP-Header":{"title":"Header","links":["Language/Python/FastAPI/FastAPI"],"tags":["Python/FastAPI"],"content":"Header\n\nFastAPI 에서는 HTTP Header 를 Function Parameter 로 쉽게 받을 수 있음 \nHeader() Function 를 사용하여 Specific Header Value 를 Parameter 로 받을 수 있음\n\nEx) greeting Argument 를 HTTP Header 로 전달\n\n\n\nExample\n\n\n                  \n                  Custom \n                  \n                \n\n\n\n                  \n                  Return String Header \n                  \n                \n\nfrom fastapi import FastAPI, Header\n \napp = FastAPI()\n \n@app.get(&quot;/hi&quot;)\ndef greet(who: str = Header()):\n    return f&quot;Hello? {who}?&quot;\n\n\n\n\nHTTP Header ‘Name:Value’ 형태로 지정\n\n\n\n\n                  \n                  HTTPie \n                  \n                \n\nhttp -v localhost:8000/hi who:Mom\n\n\n\n\n\n\n                  \n                  User-Agent \n                  \n                \n\n\n\nFastAPI 는 HTTP Header Key 를 lowercase &amp; hyphen( - ) 을 underline( _ ) 으로 Conversion 함\n\n\n따라서 HTTP User-Agent Header Value 출력 가능\n\n\n\n\n\n\n                  \n                  Return User-Agent Header \n                  \n                \n\nfrom fastapi import FastAPI, Header\n \napp = FastAPI()\n \n@app.get(&quot;/agent&quot;)\ndef greet(user_agent: str = Header()):\n    return user_agent\n\n\n\n\n                  \n                  HTTPie \n                  \n                \n\nhttp -v localhost:8000/agent\n\n\n\n"},"Language/Python/FastAPI/FastAPI-HTTP-Request":{"title":"HTTP Request","links":["Web/REST","Language/Python/FastAPI/FastAPI-HTTP-Header","Language/Python/FastAPI/FastAPI-URL-Path","Language/Python/FastAPI/FastAPI-Query-Parameter","Language/Python/FastAPI/FastAPI-Body","Language/Python/FastAPI/FastAPI-Multiple-Request-Data","Language/Python/FastAPI/FastAPI-Request-권장-사항"],"tags":["Python/FastAPI","Web/HTTP"],"content":"HTTP Request\nExample\n\n\n                  \n                  1. HTTP Request \n                  \n                \n\nGET /hi HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nConnection: keep-alive\nHost: localhost:8000\nUser-Agent: HTTPie/3.2.1\n\n\nHTTP Request 의 Structure\n\n동사(GET, POST, etc.) &amp; Path(/hi, etc.)\nAll Query Parameter(URL 의 ? 뒤에 오는 부분, 현재 Request 에는 X)\n기타 HTTP Header\nRequest Body Content X\n\nFastAPI 의 HTTP Request 해석\n\nHeader: HTTP Header\nPath: URL\nQuery: Query Parameter(URL 끝의 ? 뒤)\nBody: HTTP Body\n\nFastAPI 의 장점\n\nHTTP Request Data 에 직접 접근 가능\nPath Function 내에서 필요한 Argument 를 직접 선언 가능\nDependency Injection 기법 사용\n\nExample Application 확장\n\n{Custom} Parameter Add 예정\nParameter 전달 방법\n\nURL Path\nQuery Parameter\nHTTP Body\nHTTP Header\n\n\n\nSubhedding\n\nURL Path\nQuery Parameter\nBody\nHeader\nMultiple Request Data\nRequest 권장 사항\n"},"Language/Python/FastAPI/FastAPI-HTTP-Response":{"title":"HTTP Response","links":["Language/Python/FastAPI/FastAPI","Web/JSON--and--API-Data-Type","Language/Python/FastAPI/FastAPI-Status-Code","Language/Python/FastAPI/FastAPI-Header","Language/Python/FastAPI/FastAPI-Response-Type","Language/Python/FastAPI/FastAPI-Type-Conversion","Language/Python/FastAPI/FastAPI-Model-Type--and--Response-Model"],"tags":["Python/FastAPI","Web/HTTP"],"content":"HTTP Response\n\nFastAPI 는 기본적으로 All Return Value 를 JSON 으로 Conversion\n\nEx)  String, Python Built-in Type, Pydantic Model, etc.\n\n\nHTTP Response Header 는 &#039;Content-type&#039;: application 이 포함\n이는 API Development 를 Simplification 하기 위한 FastAPI 의 Default Setting\n\nSubheadding\n\nStatus Code\nHeader\nResponse Type\nType Conversion\nModel Type &amp; Response Model\n\n이러한 Feature 는 FastAPI 를 사용할 때 일관된 JSON Response 를 쉽게 생성할 게 있게 해준다."},"Language/Python/FastAPI/FastAPI-Header":{"title":"Header","links":[],"tags":["Python/FastAPI","Web/HTTP"],"content":"Header"},"Language/Python/FastAPI/FastAPI-Introduction":{"title":"Introduction","links":["Language/Python/Python-Web-Framework","Language/Python/Type-Hint","Web/Concurrency"],"tags":["Python/FastAPI"],"content":"Introduction\nFeature\n\nWeb API Develop 에 특화된 Python Web Framework\nHigh Performance &amp; Fast Development Speed 제공\nType Hint &amp; Pydantic Model 를 통한 Code 품질 향상\nAutomatic Documentation &amp; Test Page Create\n\nKey Features\n\nPython Type Hint 활용\nStarlette 를 통한 Asynchronous 지원\nPydantic 을 이용한 Data Definition &amp; Validation\n다양한 통합 기능 제공\n\n장점\n\nHigh Performance1\n직관적이고 이해하기 쉬운 Code\nBug 감소 &amp; Code Quality 향상\nOpenAPI 기반의 편리한 Documentation\n\nFastAPI 는 이러한 특징들을 조합하여 RESTful Web Service Development 에 최적화된 Environment 를 제공\nFootnotes\n\n\nNode.js,  Go 와 비견될 만함 ↩\n\n\n"},"Language/Python/FastAPI/FastAPI-Model-Type--and--Response-Model":{"title":"Model Type & Response Model","links":[],"tags":["Python/FastAPI"],"content":"Model Type &amp; Response Model"},"Language/Python/FastAPI/FastAPI-Multiple-Request-Data":{"title":"Multiple Request Data","links":["Language/Python/FastAPI/FastAPI-URL-Path","Language/Python/FastAPI/FastAPI-Query-Parameter","Language/Python/FastAPI/FastAPI-Body","Language/Python/FastAPI/FastAPI-HTTP-Header","Web/Pagination"],"tags":["Python/FastAPI"],"content":"Multiple Request Data\n\n\n하나의 FastAPI Path Function 에서 여러 Data Source 를 동시에 사용 가능 \n\n\nExample of Data Source \n\nURL \nQuery Parameter \nHTTP Body \nHTTP Header\nCookie1 \n\n\n\nDeveloper 는 이러한 Data 를 처리하기 위한 Custom Dependency Function 을 작성할 수 있음 \n\n\n이 Feature 을 활용하여 Pagination  or  Authentication 같은 Advance Feature 을 구현할 수 있음 \n\n\n이러한 접근 방식은 다양한 Source 에서 Data 를 유연하게 조합하고 Processing 할 수 있게 해줌 \n\n\nFootnotes\n\n\nServer 가 User 의 Web browser 에 전송하는 Small Data Fragment ↩\n\n\n"},"Language/Python/FastAPI/FastAPI-Query-Parameter":{"title":"Query Parameter","links":["Language/Python/FastAPI/FastAPI-HTTP-Request"],"tags":["Python/FastAPI"],"content":"Query Parameter\nURL 에서 ? 뒤에 오는 Name=Value 형태의 문자열로,  &amp; 로 구분된다.\nExample\n\n\n                  \n                  Query Parameter \n                  \n                \n\n\n\n                  \n                  Return Custom Query Parameter \n                  \n                \n\nfrom fastapi import FastAPI\n \napp = FastAPI()\n \n@app.get(&quot;/hi&quot;)\ndef greet(who):\n    return f&quot;Hello? {who}?&quot;\n\n\n\nEndpoint Function 는 greet(Custom) 로 정의 \n@app.get(&quot;/hi/{Custom}&quot;) 이 존재 X \n\nwho 가 Query Parameter 라고 가정\n\n\n\n\n\n\n\n                  \n                  Test \n                  \n                \n\n\n\n                  \n                  Browser \n                  \n                \n\n\nhttp://localhost:8000/hi?who=Mom\n\n\n\n\n\n                  \n                   HTTPie\n                  \n                \n\n\n\n                  \n                  bash \n                  \n                \n\nhttp -b localhost:8000/hi?who=Mom\n\n\n\n\n                  \n                  zsh \n                  \n                \n\nhttp -b localhost:8000/hi\\?who=Mom\n\n\n\nbash &amp; zsh 는 String Parsing 에서 약간의 차이가 존재\n\n\nbash : ?\n\n\nzsh : \\?\n\n\n\n\n\n\n                  \n                  Argument \n                  \n                \n\nhttp -b localhost:8000/hi who==Mom\n\n\n\n이러한 Argument 를 두 개 이상 사용 가능 \n공백으로 구분된 Argument 를 입력하는 더 쉬움\n\n\n\n\n\n                  \n                   Requests\n                  \n                \n\n\n\n                  \n                  Basic \n                  \n                \n\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; r = requests.get(&quot;http://localhost:8000/hi?who=Mom&quot;)\n&gt;&gt;&gt; r.json()\n\n\n\n\n                  \n                  Parameter \n                  \n                \n\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; params = {&quot;who&quot;: &quot;Mom&quot;}\n&gt;&gt;&gt; r = requests.get(&quot;http://localhost:8000/hi&quot;, params=params)\n&gt;&gt;&gt; r.json()\n\n\n\n\n\n다른 방식으로 String 을 제공하고,  이를 Path 로 전달해 Final Response 로 보냄\n\n\n"},"Language/Python/FastAPI/FastAPI-Request-권장-사항":{"title":"Request 권장 사항","links":["Web/REST","Language/Python/Type-Hint","Web/Service--and--API","Web/Pagination"],"tags":["Python/FastAPI"],"content":"Request 권장 사항\n\n\nURL Argument 전달 시 RESTful 가이드라인을 따르는 것이 좋음 \n\n\nQuery String 은 주로 선택적 Argument1 에 사용\n\n\nRequest Body 는 더 큰 Input2 에 사용 \n\n\nData 정의에 Type Hint 를 제공하면 Pydantic 이 자동으로 Argument 의 Type 과 존재 여부를 검사할 수 있음\n\n\n이러한 권장 사항을 따르면 API Design 이 더 명확하고 일관성 있게 되며, Data 유효성 Test 도 향상됨\nFootnotes\n\n\nPagination ↩\n\n\nEx)  전체  or  부분 Model ↩\n\n\n"},"Language/Python/FastAPI/FastAPI-Response-Type":{"title":"Response Type","links":[],"tags":["Python/FastAPI"],"content":"Response Type"},"Language/Python/FastAPI/FastAPI-Status-Code":{"title":"Status Code","links":[],"tags":["Python/FastAPI"],"content":"Status Code\nDefault\n\nNormal : 200\nException : 4xx\n\n지정 방법\n\nPath Decorator 에서 직접 지정 가능\n모든 것이 정상일 때 Return 할 Code 명시\n\nException 은 자체 Code 를 생성해 재정의\n\n\n\n\n\n                  \n                  HTTP Status Code \n                  \n                \n\n\n\n                  \n                  hello.py \n                  \n                \n\n@app.get(&quot;/happy&quot;)\ndef happy(status_code=200):\n    retrun &quot;:)&quot;\n\n\n\n\n                  \n                  HTTPie \n                  \n                \n\nhttp localhost:8000/happy\n\n\n\n"},"Language/Python/FastAPI/FastAPI-Type-Conversion":{"title":"Type Conversion","links":[],"tags":["Python/FastAPI"],"content":"Type Conversion"},"Language/Python/FastAPI/FastAPI-URL-Path":{"title":"URL Path","links":["Language/Python/Python-Variable","Language/Python/FastAPI/FastAPI","Language/Python/FastAPI/FastAPI-Application","Web/JSON--and--API-Data-Type"],"tags":["Python/FastAPI"],"content":"URL Path\nExample\n\n\n                  \n                  URL Path \n                  \n                \n\n\n\n                  \n                  Return Custom Path \n                  \n                \n\nfrom fastapi import FastAPI\n \napp = FastAPI()\n \n@app.get(&quot;/hi/{who}&quot;)\ndef greet(who):\n    return f&quot;Hello? {who}?&quot;\n\n\n\n\n동적 URL Path 를 만들기 위해 @app.get(&quot;/hi/{Custom}&quot;) 형식 사용 \n\n\nPath Function(Ex: def greet(Custom):) 에서 이 Variable 를 사용 가능\n\n\n\n\n                  \n                  Caution \n                  \n                \n\n\n수정된 URL String(“/hi/{Custom}”) 에 Python f-string 사용 X \n중괄호는 FastAPI 의 Path Parameter 문법 \nCode 변경 후 Uvicorn 이 Restart 됨 \n\nRestart 하지 않을 경우 Create a New File 후 다시 실행하길 권함\nUvicorn 에서 Error 가 발생한다면 Uvicorn 자체 Problem 라기보다 오타가 있을 확률 큼\n\n\n\n\n\n\n\n\n\n                  \n                  Test \n                  \n                \n\n\n\n                  \n                  Browser \n                  \n                \n\n\nhttp://localhost:8000/hi/Mom\n\n\n\n\n\n                  \n                  HTTPie \n                  \n                \n\nhttp localhost:8000/hi/Mom\n\n\n\n\n                  \n                  Requests \n                  \n                \n\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; r = requests.get(&quot;http://localhost:8000/hi/Mom&quot;)\n&gt;&gt;&gt; r.json()\n\n\n\n이 방식으로 URL 의 일부를 동적으로 Processing 가능 \nResponse 는 JSON Type 으로 Return\n\n\n"},"Language/Python/FastAPI/FastAPI":{"title":"FastAPI","links":["Language/Python/Type-Hint","Language/Python/Python-API--and--Service","Language/Python/Python-Web-Framework","Language/Python/FastAPI/FastAPI-Introduction","Language/Python/FastAPI/FastAPI-Application","Language/Python/FastAPI/FastAPI-HTTP-Request","Language/Python/FastAPI/FastAPI-HTTP-Response"],"tags":["Python/FastAPI","Web/Framework"],"content":"FastAPI\n\n\n\n                  \n                  Sebastian Ramirez, FastAPI Developer \n                  \n                \n\nFastAPI 는 Standard Python Type Hint 를 기반으로,  Python 3.6 이상에서 API 를 구축하는 현대적이고 빠른(고성능) Web Framework 다.\n\n\nSubtitle\n\n\nIntroduction\n\n\n\n\n\nApplication\n\n\n\n\n\nHTTP Request\n\n\n\n\n\nHTTP Response\n\n"},"Language/Python/Poetry":{"title":"Poetry","links":["footnote-install","footnote-pinning"],"tags":["Python"],"content":"Poetry\nIntrodution\n\nPython Virtual Environment 와 Package Management 를 위한 Tool\npip 와 venv 의 기능을 결합하여 사용 편의성 향상\n\nInstallation &amp; Usage\n\npip install poetry\npoetry add1 &amp; poetry install2\n\nPoetry VS pip\n\n둘 다 Package Download &amp; Management 기능 제공\nConfiguration File\n\npyproject.toml / requirements.txt\n\n\nPackage Dependency Management 기능 제공\n\nVersion Management\n\nPackage Version 을 최소, 최대, 범위 또는 정확한 값3으로 지정 가능\nProject Growth 에 따른 Managing Dependency Package CHanges 에 중요\n\n\nFootnotes\n\n  New Dependency(Package) 을 Project 에 Add\n    \n       File 을 자동으로 Update 하여 New Dependency 를 기록\n      Added Package 와 The dependencies 즉시 Install\n      Ex) poetry add requests\n        ↩\n      \n    \n  \n  \n  pyproject.toml 에 명시된 All dependencies 를 Install\n    \n      이미 Install 된 Packages 는 건너뛰고, Missing Package 만 Install \n      Project 의 Virtual Environment 을 Create  or  Update\n      New Environment 에서 Project 를 Configure  or  Another Developer 와 Same Environment 을 구성할 때 사용\n        ↩\n      \n    \n  \n"},"Language/Python/Python-API--and--Service":{"title":"API & Service","links":["Language/Python/Type-Hint"],"tags":["Python","API"],"content":"API &amp; Service\nModule &amp; Package 의  중요성\n\nStructuring Large-Scale Application 에 필수적\n커다란 진흙 뭉치1 방지\nWeb Service 에서도 Layer Separation 유지에 도움\n\nPython Standard Data Structure\n\n매우 유연하고 범용적\n\n고급 모델링\n\n계층 간 통신을 개선하기 위한 높은 수준의 Module 정의\nType-Hint2 활용\n\nFootnotes\n\n\nStructure 가 없고 다루기 어려운 Status ↩\n\n\nPython 의 최근 추가 기능,  Module 정의에 활용됨 ↩\n\n\n"},"Language/Python/Python-Variable":{"title":"Variable","links":[],"tags":["Python"],"content":"Variable\nObject\n\nEvery Individual Piece of Data 을 감싸는 Structure\n\n고유 ID\nHardware 와 일치하는 저수준의 Type\nSpecific Value(Physical Bit)\nObject1 를 Reference 하는 Variable 의 수를 나타내는 Reference Count\n\n\nObject 수준에서 강 Type2을 가짐\n\nVariable\n\nObject 를 가리키는 Name 일 뿐\nMemory 의 Value 을 직접 가리키지는 않음\nObject 와 일시적으로 Connect\n\nAnother Language 와의 차이점\n\n많은 Language 에서 Variable 는 Memory 의 Value 를 직접 가리킴3\nPython 은 Object 를 Reference 하는 방식으로 작동\n\nVariable 할당\n\nImmutable Object 에 New Value 할당 시 New Object 생성\n이전 Object 는 Reference Count 가 0 이 되면 Memory 에서 Delete\n\nScope\n\nName 이 동일한 Object 를 가리키는 Code Area\nAnother Scope 에서 Same Name 사용 가능\n\nCaution\n\nVariable 가 Program 전체에서 Another Object 를 Reference 할 수 있음\n의미 있는 Variable Name 사용 권장\n\n이러한 특성들로 인해 Python 의 Variable 와 Object Control 방식은 독특하며,  이를 이해하는 것이 효과적인 Python Programming 에 중요\n\nFootnotes\n\n  Software 세계에서 Object 라는 용어는 무수히 많은 의미로 통용\n    ↩\n  \n  \n  Type 은 변경되지 않지만 Value 은 바뀔 수 있음\n    \n      값을 변경할 수 있으면 Mutable\n      값을 변경할 수 없으면 Immutable\n        ↩\n      \n    \n  \n  \n  대표적으로 C Language,  C 가 Python 보다 빠르다는 얘기를 들어본 적이 있다면 이에서 비롯된 것\n    ↩\n  \n"},"Language/Python/Python-Version":{"title":"Python Version","links":["Language/Python/FastAPI/FastAPI","asyncio"],"tags":["Python"],"content":"Version\n\n앞으로 제시될 Code 를 실행하기 위해선 Python 3.7 이상 필요\nFastAPI 의 핵심 요구사항인 Type Hint 와 asyncio 같은 기능이 존재\n지원 기간이 긴 Python 3.9 이상 사용하기를 권장\n"},"Language/Python/Python-Virtual":{"title":"Virtual Environment","links":[],"tags":["Python"],"content":"Virtual Environment\n필요성\n\n\nSystem Python 설치에 영향을 주지 않고 Package 를 관리하기 위함\n\n\nProject 별 Independent Python Environment 를 만들기 위함\n\n\n특징\n\n특정 Directory 에 Package 를 설치하고 관리\nActivate 시 해당 Environment 의 Package 를 우선적으로 사용\n\n장점\n\n여러 Version 의 Python 사용 가능\nProject 별 Package 관리 용이\n설치된 Package 의 명확한 파악 가능\n\n활용 방법\n\n\nPython 3.4 이상에서는 venv Module 사용\n\n\nStandalone Program  or  Python Module 로 실행 가능 \n\n\nStandalone Program\nvenv $name\n\n\n\nPython Module\npython3 -m venv $name\n\n\n\nActivate\nsource $name/bin/activate\n\n\n\nDeactivate\ndeactivate\n\n\n\n사용 시 주의사항\n\nSystem Python File 은 변경하지 말 것\npip 는 기본적으로 System Python 에 영향을 주지 않음\n"},"Language/Python/Python-Web-Framework":{"title":"Web Framework","links":["Web/HTTP","Python-Web-Framwork","Web/Concurrency","Language/Python/FastAPI/FastAPI"],"tags":["Python","Web/Framework"],"content":"Web Framework\n주요 역할\n\nHTTP 로 전달되는 Byte 와 Python Data Structure 간 변환\nDevelop 노력 절감, 필요한 기능이 없으면 해결해야1 할 수 있음\n\nWSGI(Web Server Gateway Interface)\n\nPython 표준 사양\nApplication Code 를 Synchronous 으로 Web Server 에 Connect\n기존 Python Web Framwork 의 기반\n\nConcurrency 의 중요성\n\nSynchronous Communication 의 한계(CPU 보다 느린 Task idle time)\n더 나은 Concurrency 필요성 대두\n\nASGI(Asynchronous Server Gateway Interface)\n\nConcurrency 개선을 위해 최근 Develop 됨\n\n활용 Tip\n\n가능한 기존 Solution 활용2\n필요시 Open Source Framwork 수정 가능3\n\nSubtitle\n\nDjango \nFlask \nFastAPI\n\nFootnotes\n\n\nWeb Framwork 의 내부 Source 를 입맛에 맞게 고친다는 뜻 ↩\n\n\n바퀴를 다시 발명하지 말라는 뜻 ↩\n\n\n원하는 기능이나 Issue 가 있다면 이를 보고하고 직접 수정 사항을 제출해볼 것 ↩\n\n\n"},"Language/Python/Python":{"title":"Modern Python","links":["Language/Python/Python-Version","Testing","Language/Python/FastAPI/FastAPI-Application","Language/Python/Python-API--and--Service","Language/Python/Python-Variable","Language/Python/Type-Hint","Py-Data-Structure","Language/Python/Python-Web-Framework","Virtual","Language/Python/Poetry"],"tags":["Language","Python"],"content":"Python\ngantt\n    title Python Release Cycle\n    dateFormat  YYYY\n    axisFormat %Y\n\n    section Python 2.6\n    End-of-Life : crit, 2008, 2013\n\n    section Python 2.7\n    End-of-Life : crit, 2010, 2020\n\n    section Python 3.0\n    End-of-Life : crit, 2008, 2009\n\n    section Python 3.1\n    End-of-Life : crit, 2009, 2012\n\n    section Python 3.2\n    End-of-Life : crit, 2011, 2016\n\n    section Python 3.3\n    End-of-Life : crit, 2012, 2017\n\n    section Python 3.4\n    End-of-Life : crit, 2014, 2019\n\n    section Python 3.5\n    End-of-Life : crit, 2015, 2020\n\n    section Python 3.6\n    End-of-Life : crit, 2016, 2021\n\n    section Python 3.7\n    End-of-Life : crit, 2018, 2023\n\n    section Python 3.8\n    Security : done, 2019, 2024\n\n    section Python 3.9\n    Security : done, 2020, 2025\n\n    section Python 3.10\n    Security : done, 2021, 2026\n\n    section Python 3.11\n    Security : done, 2022, 2027\n\n    section Python 3.12\n    Bugfix  : active, 2023, 2028\n\n    section Python 3.13\n    Pre-release : active, 2024, 2029\n\n    section Python 3.14\n    Feature : active, 2025, 2030\n\nTool\n\nVersion\nPackage Management1\nCode Formatting2\nTesting3\nSource control4 &amp; Continuous Integration(CI)5\nWeb Tool\n\nSubtitle\n\nAPI &amp; Service \nVariable \nType-Hint \nData Structure \nWeb Framework\n\n\nFootnotes\n\n  전통적으로는 pip 를 사용,  Virtual Environment 를 사용하거나 Poetry 같은 대체제 고려 가능\n    ↩\n  \n  중요하지만 다른 것들에 비해 중요도 떨어짐,  불필요한 논쟁을 피하기 위해선 자동화된  Formatting Tool 을 사용\n    \n      Ex)  black,  pip install black\n        ↩\n      \n    \n  \n  \n  unittest 가 Standard Python Test Package\n    \n      하지만,  대부분의 Python Developer 는 pytest 사용\n      Ex) pip install pytest\n        ↩\n      \n    \n  \n  \n  Git 이 현재 가장 보편적인 시스템\n    \n      Github &amp; GitLab 등의 Platform 에서 Git Storage Hosting\n      All Programming Languages 에  사용 가능\n        ↩\n      \n    \n  \n  \n  pre-commit\n    \n      Local 에서 Commit 전 Test 실행 가능\n      Ex)  black,  pytest\n      Remote Repository 에 Push 후 추가 CI Test 가능\n        ↩\n      \n    \n  \n"},"Language/Python/Type-Hint":{"title":"Type Hint","links":[],"tags":["Python"],"content":"Type Hint\n도입\n\nPython 3.6 부터 Type Hint 기능이 Add\n\n목적\n\nVariable 이 Reference 하는 Object 의 Type 을 선언하기 위함\n\n특징\n\n실행 중인 Python Interpreter 에 영향 X\nVariable 사용의 일관성 유지를 위한 Tool 로 활용\nmypy 같은 Standard Type 검사기와 함께 사용 가능\n\n장점\n\nProgrammer 의 실수 방지에 도움1\nCode 의 가독성과 유지보수성 향상\n\nCaution\n\n강제성이 없는 선택적 기능\nLint Tool 과 유사하지만 예상치 못한 용도로도 사용 가능\nCode 의 품질을 높이는 데 도움을 주지만,  Python 의 동작 특성을 해치지 않는 선에서 적절히 사용할 것\n\nFootnotes\n\n\nEx) count: int 와 같이 Variable 의 Type 을 명시할 수 있음 ↩\n\n\n"},"Language/Rust/Rust":{"title":"Rust","links":[],"tags":["Language","Rust"],"content":""},"Linux/Directory-Structure":{"title":"Directory structure","links":[],"tags":["OS/Linux"],"content":"\nLinux 는 Unix 와 마찬가지로 모든 대상들을 파일로 관리\nDirectory file 들을 관리하기 위해 계층적으로 구성하며 이를 Tree structure\n모든 Directory 의 최상의 Directory 를 Root directory(/)\n\n\n  \n    Directory Location\n    Directory Name\n    Features\n  \n  \n    /\n    /\n    모든 Directory 의 최상의 Directory\n  \n  \n    /bin\n    bin\n    Default command 가 저장된 Directory자주 사용되는 Command 들이 해당 Directory 에 저장\n  \n  \n    /boot\n    boot\n    리눅스의 부팅에 필요한 Information 을 가진 File 들이 저장된 Directory\n  \n  \n    /dev\n    dev\n    시스템 장치 File 을 저장하고 있는 Directory물리적 장치들이 File 형식으로 저장되어 있음\n  \n  \n    /etc\n    etc\n    Linux 의 Preferences file 이 저장된 Directory\n  \n  \n    /home\n    home\n    User 의 Home directory 가 존재하는 곳User를 추가할 때 마다 User ID 명과 동일한 Directory 가 생성된\n  \n  \n    /lib\n    lib\n    Kernel 이 필요로 하는 Libaray, Kernel Module file 이 존재하는 Directory\n  \n  \n    /media\n    media\n    외부 기억장치들의 Mount 연결 시 사용되는 Directory\n  \n  \n    /mnt\n    mnt\n    사용자가 직접 외부 장치들을 Mount 할 때 사용되는 Directory\n  \n  \n    /opt\n    opt\n    추가 응용 프로그램 Package 가 설치되는 Directory\n  \n  \n    /proc\n    proc\n    최상위 Root directory 와 전혀 다른 directory관리자 계정 root 의 Home directory\n  \n  \n    /sbin\n    sbin\n    System Binary file, ifconfig, ethtool 와 같은 System commands 을 저장하고 있는 Directory\n  \n  \n    /usr\n    usr\n    Nomal User 들이 사용하는 Directory\n  \n  \n    /var\n    var\n    Log file 수집, Database Caching file, Web Server image 등 다양한 File 이 존재하는 Directory\n  \n  \n    /sys\n    sys\n    Device 를 관리하기 위한 Virtual File System Directory\n  \n  \n    /run\n    run\n    실행 환경 변수(Run-time variable)를 관리하는 Directory부팅한 후의 System Information 을 관리하는 Directory\n  \n  \n    /tmp\n    tmp\n    임시 File 을 저장하기 위한 Directory\n  \n  \n    /lost + found\n    lost + found\n    Trash 와 같은 개념으로, 삭제된 File 이 저장된 Directory\n  \n"},"Linux/Directory-commands":{"title":"Directory","links":[],"tags":["OS/Linux"],"content":"1. Directory\n\npwd : 현재 위치 확인\ncd : 이동\nls : Directory 안 내용 출력\n\nls -a : 숨긴 파일 모두 출력\nls -d : Directory 자체의 정보 출력\nls -i : incode1 번호 출력\nls -A : ., ..를 제외한 모든 목록 출력2\nls -F : File 종류 표시3\nls -L : Symbolic link 의 경우 원본 File 의 정보 출력\nls -R : 하위 Directory 의 목록 출력\n\n\nmkdir : Directory 생성\n\nmkdir -p : SubDirectory 를 계층적으로 생성할 때 중간 단계의 Directory 를 자동 생성\n\n\nrmdir : Directory delete\n\nFootnotes\n\n\nFile, Directory 에 관한 정보를 가지는 숫자 ↩\n\n\nFile, Directory 의 이름 앞에 붙으면 Hidden File, Directory  - . : Current Directory  - .. : Parent Directory ↩\n\n\n/ : Directory  * : 실행 가능한 File(executable)  @ : 바로가기(Symbolic link)  | : AND(Pipe) ↩\n\n\n"},"Linux/Docker/Docker":{"title":"Docker","links":[],"tags":["OS/Linux"],"content":"Docker\nImage\n\n\n타 개발자 및 기업들이 배포하는 Docker Image 는 기본적으로 Root 권한\n\n\nUbuntu Desktop 사용 시 사용하는 건 User 권한,  고로 Container 에서 Host Computer 로 여러 Data &amp; GUI 를 건네받을 시 여러 권한문제가 발생하게 됨\n\n이를 해결하기 위해선\n\nuser 권한으로 작동하도록 dockerfile 작성 후 빌드 후 사용\napt install sudo1,  adduser2,  usermod -aG sudo {User name}3,  su4 Command 를 통해 User 권한으로 사용 \n\n\n\n\n\n현재 연구실의 Dockerfile 을 사용하고 싶다면 아래의 이미지를 활용할 것(단 Pytorch &amp; Tensorflow 같은 딥러닝 라이브러리를이 설치되지 않았으므로 주의 요망)\ndocker pull taehun3446/setup:user\n\n\nContainer\n\n\n                  \n                  Tip\n                  \n                \n\n\n\n                  \n                  Oh My Zsh 의 docker plugin 적용 X\n                  \n                \n\ndocker run -it --rm --gpus all -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=unix$DISPLAY {docker image}\n\n\n\n\n                  \n                  Oh My Zsh 의 docker plugin 적용 O\n                  \n                \n\ndrit --rm --gpus all -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=unix$DISPLAY {docker image}\n\n\nArgument\n\n-it5\n\n-i : 상호 Input/Output\n-t : tty6 를 활성화하여 Shell7 을 사용하도록 Container 에서 설정8 \n\n\n--rm : 접속 중인 Shell 종료 시 Container 바로 Delete \n--gpus all : Container 에서 Host 의 GPU 전체9를 사용할 수 있게 함(nvidia-smi10 로 확인 가능) \n-v : Host 의 Directory 를 Container 에 Mount 시킴 \n-e : Parameter 를 통해 Host 의 Environment Variable 를 Container 에 넘겨줌11\n\n\n\nFootnotes\n\n\nDocker Container 안에서 apt 를 통하여 설치하고자 한다면 항상 우선적으로 apt update 실시하는 걸 잊지 말 것Docker Image 는 용량 절감을 위해 항상 rm -rf /var/lib/apt/lists/* 로 APT 패키지 관리자의 캐시된 패키지 목록을 삭제한 상태이기 때문 ↩\n\n\nUser Add ↩\n\n\nsudo Command 를 사용할 수 있도록 Group 에 Add ↩\n\n\nUser Conversion ↩\n\n\n이 Command 를 안써도 되지만 하나라도 쓰지 않을 경우 Shell 사용 불가 ↩\n\n\nUser 와 Computer 가 상호작용하는 Text 기반의 Interface,  Terminal ↩\n\n\nUser 가 Computer 가 상호작용할 수 있도록 Command 를 입력하고 그 결과를 출력하는 Program,  Command Interpreter(Bash, Zsh, Fish) ↩\n\n\ntty,  Shell 서로 비슷해보이지만 다른 개념,  이 점에 더 알고 싶다면 OS &amp; Linux 를 공부해볼 것 ↩\n\n\n단일 GPU 넘어서 다중 GPU 를 활용할 경우 Containers,  Models 를 각 GPU 를 지정해서 실행 &amp; 연산 가능 ↩\n\n\nHost 에 Nividia Driver &amp; Nvidia Container Toolkit 을 설치하는 것을 잊지 말 것 ↩\n\n\nDocker 는 기본적으로 Terminal 기반으로 동작하기에 GUI 를 가지고 있지 않음,  GUI 를 활용하기 위해선 필수 ↩\n\n\n"},"Linux/File":{"title":"File","links":[],"tags":["OS/Linux"],"content":"2. File\n\ncat : File 의 내용 출력\n\ncat -n : Row number 붙여 출력\n\n\nmore : File 의 내용을 화면 단위로 출력\n\nmore +number : 출력을 시작할 Row number 를 지정\n\n\nless : File 의 내용을 화면 단위로 출력1\nhead : File 의 1 ~ n Row 까지 출력\n\nhead -Line : 출력할 Row 수를 지정\n\n\ncp : File 이나 Directory 복사\n\ncp -r : SubDirectory &amp; Subfile 까지 모두 복사\ncp -v : 복사 진행 상태 출력\ncp -p : File or Directory 를 복사할 때 복사 대상의 User, Group, Permissions\ncp -i : 복사 대상 File 이 이미 해당 위치에 있다면 User 한테 Overdrive 여부 묻고 복사\ncp -f : 복사 대상 File 이 이미 해당 위치에 있다면 File 을 지우고 강제로 복사\n\n\nrm : File 이나 Directory delete\n\nrm -i : User 한테 여부 묻고 delete\n\n\nln : File link 생성\n\nln -s : Symbolic link file 생성\n\n\ntouch : Empty file 생성\ngreb : (File 내 search) 지정한 Pattern 포함된 Line 찾기   Ex) grep [option][pattern][file]\n\ngrep -c : 일치하는 Row 의 수 출력\ngrep -i : 대소문자 구별 X\ngrep -v : 일치ㅏ하지 않는 Row 만 출력\ngrep -n : 포함된 Row number 함께 출력\ngrep -l : Pattern 이 포함된 File name 출력\ngrep -w : Word 와 일치하는 Row 만 출력\ngrep -x : Line 과 일치하는 Row 만 출력\ngrep -r : SubDirectory 를 포함한 모든 File 에서 search\ngrep -m number 최대로 표시될 수 있는 결과를 제한\ngrep -E : 찾을 pattern 을 정규 포현식으로 찾기\ngrep -F : 찾을 pattern 을 String 으로 찾기\n\n\nfind : 지정한 Path 에서 Search 조건에 맞는 File 찾기   Ex) find [option][path][expressions]2\n\nfind -P : Symbolic link 를 따라가지 않고, Symbolic link 자체 정보 사용\nfind -L : Symbolic link 에 연결된 File 정보 사용\nfind -D : Debug message 출력\n\n\nwhereis : 지정된 Path 에서 Command 의 Binary file 이나 Maual file 의 위치를 찾음\n\nwhereis -b : Binary file 만 Search\nwhereis -m : Maual file 만 Search\nwhereis -s : Source file 만 Search\n\n\n\nFootnotes\n\n\nj : Down key  k : Up key  space bar, Ctrl + f : 다음 Page 이동 \\string : 해당 String 찾기  q : 종료 ↩\n\n\nname : 해당 이름의 File을 찾음(Regex 사용 O)  type : 지정된 File type 에 해당하는 Search for file  user : 해당 User 에게 속한 Search for file  empty : Empty directory 혹은 크기가 0인 Search for file  delete : Search된 File 혹은 Directory delete  exec : Search된 File 에 대해 지정된 Command 실행  path : 지정된 String pattern 에 해당하는 Path 에서 Search  print : Search 결과를 출력, Search 항목을 newline 으로 구분(Default)  print0 : Search 결과를 출력, Search 항목을 null 로 구분  size : File size 를 사용 하여 Search for file  mindepth : Search 을 시작할 SubDirectory 최소 Depth 지정  maxdepth : Search 할 SubDirectory 의 최대 Depth 지정  atime : n 일 이내에 Acess 된 File 찾음  ctime : n 일 이내에 만들어진 File 찾음  mtime : n 일 이내에 수정된 File 을 찾음  cnewer file : 해당 File 보다 최근에 수정된 File 을 찾음 ↩\n\n\n"},"Linux/Ubuntu":{"title":"Ubuntu","links":["Linux/Directory-Structure","Linux/Directory-commands","Linux/File","Linux/vim"],"tags":["OS/Linux"],"content":"Directory Structure\nDefault Commands\n\n\nDirectory-commands\n\n\nFile\n\n\nEdit Document\n\n"},"Linux/vim":{"title":"Edit document","links":[],"tags":["OS/Linux"],"content":"3. Edit documents\n\nvi : 지정한 File 편집   PS) vim1을 더 추천\n\n: : Command mode 진입\nq : 종료\nq! : 강제 종료\nw : File 저장\nwq : 저장 후 종료\n\ninsert mode 전환\n\ni : 현재 커서 위치에 insert\nI : 현재 Row 맨 앞에 insert\na : 현재 커서 다음 위치에 insert\nA : 현재 Row 마지막에 insert\no : 아래 Row 에 insert\nO : 위 Row 에 insert\n\n\n커서 Move\n\nw : 다음 Word 첫 character 로 Move\nb : 이전 Word 첫 character 로 Move\nctrl + f : 한 Page 아래로 커서 Move\nctrl + b : 한 Page 위로 커서 Move\nG : 마지막 Row 로 커서 Move\nnumber : n Row 로 커서 Move\n\n\n내용 delete\n\nx : 현재 커서 위치의 한 character delete\nX : 현재 커서 위치 이전한 한 character delete\ndw : 현재 커서 위치의 Word delete\ndb : 현재 커서 위치 이전 Word delete\ndd : 현재 커서 위치의 Row delete\n[number]dd : 현재 커서 위치부터 아래 n Row 을 delete\nd^ : 현재 Row 에서 현재 커서 위치 이전 Row delete\nd$ : 현재 Row 에서 현재 커서 위치 이후 Row delete\n\n\nTake command\n\nu : 이전 Take command\nU : 해당 Row 에서 한 모든 Command 을 take\ne! : 마지막으로 저장한 애용 이후의 것을 모두 Take\nctrl + r : 이전 Take command 을 take\n\n\nCopy &amp; Paste\n\nyy : 현재 커서 위치의 Row 을 copy\n[number]yy : 현재 커서에서 아래의 n Row 을 copy\np : 현재 커서 위치 아래 Row 에 paste\nP : 현재 커서 위치 위 Row 에 paste\nyw : 현재 커서 이후 Copy Word\nyb : 현재 커서 이전 Copy word\n\n\nSearch\n\n/String : String 을 아래 방향으로 Search\n?String : String 을 위 방향으로 검색\nn : 다음 Search for string\nN : 이전 Search for string\n\n\nReplace\n\ns/String-1/String-2 : 현재 커서 위치 Row 에서 첫 번째 나오는 String-1 을 String-2 로 변경\n%s/String-1/String-2 : File 전체에서 모든 String-1 을 String-2 로 변경\n\n\nFile alias\n\nr [file] : 지정한 File 을 읽어 들여 현재 커서 위치로 삽입\ne : 지정한 파일로 전환 - 저장 완료 후 기능\nn : vi 시작 시 여러 File 을 지정했을 경우 다음 File 로 전환\n\n\nPreferences\n\n~/.vimrc 편집\nset nu : File 내용의 각 Row 에 Row number 표시\nset nonu : Row number 표시를 take\nset list : 눈에 보이지 않는 Special character 를 표시\nset showmode : Current mode 표시\nset noshowmode : Current mode 표시 take\nset : set으로 설정한 모든 vi Preferences 값을 출력\nset all : 모든 vi Environment variable 와 Current 값 출력\n\n\n\n\n\n\n\nFootnotes\n\n\n어느정도 익숙해진 뒤 gedit이나 vscode를 쓰지 않고 vim을 더 잘 황용하고 싶다면 nvim을 추천한다.  nvim을 IDE 처럼 쓸 수 있는 여러 프로젝트 들도 있으니 이를 참고 ↩\n\n\n"},"Project/2024-Capstone-II":{"title":"2024 스케일카 자율주행 경진대회(Auto Race)","links":[],"tags":["Project"],"content":"Capston II\n1. Vehicle Body\n\n작동 여부 확인하기\nRPLidar A1M8-R6 장착 &amp; 작동 테스트\n\nLidar Point Cloud 가공하는 법 공부\n\n\n\n2. Server\n\n클라이언트에서 영상 수신 시 서버에서 송신 테스트\nYolov5 or Yolov8 or Yolov10 테스트1\n\nFootnotes\n\n\n예정 ↩\n\n\n"},"Project/API-Server":{"title":"FMCL API Server Project","links":[],"tags":["Project"],"content":"gantt\n    title 2024년 9월 프로젝트 일정\n    dateFormat  YYYY-MM-DD\n    axisFormat %m/%d\n\n    section 개발 단계\n    서버(로컬)-클라이언트 데이터 전송 테스트 : 2024-09-01, 7d\n    도커 적용                               : 2024-09-08, 7d\n    API 서버 권한 수정 및 호출 제한         : 2024-09-15, 7d\n    통합 테스트 및 에러 체크                : 2024-09-22, 7d\n    인증 권한 토큰 작업                     : 2024-09-29, 7d\n    서버 테스트 (완성 목표)                 : 2024-10-06, 7d\n    디버깅                                  : 2024-10-13, 14d\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeekTask1th서버(로컬) - 클라이언트 간 데이터 양방향 전송 테스트2th도커 적용3thAPI 서버 권한 수정 및 클라이언트 호출 제한4th통합 테스트 및 에러 체크5th인증 권한 토큰 작업6th서버 테스트(완성 목표)7 ~ 8 th디버깅\n\n시험기간 고려해서 6주차까지 완성 후 7 ~ 8주차에 보완 &amp; 개선 중심으로 목표로 하고 있습니다.\n\n1주차 테스트\n\n파일 인덱싱 &amp; IO\n사진 Test\n녹화 영상 Test\n실시간 영상 Test\n\n\n대략 이렇게 개요를 잡고 있습니다.\n\nPS)\n진도가 늦어지는 점 죄송합니다.\n현재 Github Pages 에 공부 자료를 우선적으로 올리는 것을 중점으로 문서를 꾸려나가고 있습니다.\n시간이 되시면 혹여나 틀린 점이 있을 시 메일 보내주시면 확인하는대로 신속하게 수정해놓도록 하겠습니다."},"ROS/ROS-2":{"title":"ROS 2","links":[],"tags":["OS/Linux"],"content":""},"Reference/Real-time-3D-Traffic-Cone-Detection-for-Autonomous-Driving":{"title":"Real-time 3D Traffic Cone Detection for Autonomous Driving","links":["Reference/Real-time-3D-Traffic-Cone-Detection-for-Autonomous-Driving"],"tags":[],"content":"Abstract - 단안 카메라를 이용한 도로 장면의 의미론적 이해에 상당한 진전이 있었습니다. 그러나 이는 주로 자동차, 자전거 이용자, 보행자와 같은 특정 클래스에 초점을 맞추고 있습니다. 본 연구는 자율주행 차량의 맥락에서 교통 통제에 중요한 물체 범주인 교통 콘을 조사합니다. 단안 카메라의 이미지를 사용한 3D 물체 감지는 본질적으로 불량 설정 문제입니다. 본 연구에서는 교통 콘의 독특한 구조를 활용하고 이 문제를 해결하기 위한 파이프라인 접근 방식을 제안합니다. 구체적으로, 우리는 먼저 수정된 2D 물체 감지기로 이미지에서 콘을 감지합니다. 이어서 우리의 심층 구조 회귀 네트워크의 도움으로 교통 콘의 키포인트를 인식하는데, 여기서 교차비가 투영 불변이라는 사실이 네트워크 정규화에 활용됩니다. 마지막으로, 키포인트 회귀에서 얻은 대응을 사용하여 고전적인 원근 n-점 알고리즘을 통해 콘의 3D 위치를 복원합니다. 광범위한 실험을 통해 우리의 접근 방식이 실시간으로 교통 콘을 정확하게 감지하고 3D 세계에서의 위치를 추정할 수 있음을 보여줍니다. 제안된 방법은 실시간 자율 시스템에도 배포되었습니다. 저전력 Jetson TX2에서 효율적으로 실행되어 정확한 3D 위치 추정을 제공하며, 레이스카가 교통 콘으로 표시된 보이지 않는 트랙을 매핑하고 자율 주행할 수 있게 합니다. 강력하고 정확한 인식의 도움으로, 우리의 레이스카는 2018년 이탈리아와 독일에서 열린 두 Formula Student 대회에서 모두 우승했으며, “gotthard driverless” 무인 플랫폼에서 최고 속도 54km/h로 주행했습니다 (youtu.be/HegmIXASKow). 전체 파이프라인, 매핑 및 내비게이션의 시각화는 우리의 프로젝트 페이지 people.ee.ethz.ch/˜tracezuerich/TrafficCone/에서 확인할 수 있습니다.\n\nI. Introdution\n자율주행은 컴퓨터 비전, 로봇공학, 그리고 기계학습 커뮤니티가 공동으로 해결해야 할 가장 흥미로운 문제 중 하나가 되었습니다1, 2, 3, 4. 자율주행 분야를 발전시키기 위해 수많은 연구가 이루어졌고, 이는 몇 년 안에 완전 자동화된 자동차를 약속하는 야심찬 발표로 이어졌습니다. 그러나 악천후와 변화하는 조명 조건에 대한 필요한 견고성5, 6, 7, 또는 도로 공사와 사고와 같은 일시적이고 예측할 수 없는 상황에 대처할 수 있는 능력8과 같은 중요한 기술적 과제들은 인간 운전자가 자율주행에 자리를 내주기 전에 극복되어야 합니다.\n교통 표지판, 신호등, 교통 콘과 같은 교통 통제 장치들은 안전한 운전을 보장하고 도로에서의 사고를 예방하는 데 중요한 역할을 합니다. 최근 몇 년간 교통 표지판9, 10과 신호등11, 12 감지에 큰 진전이 있었습니다. 그러나 교통 콘은 아직 적절한 주목을 받지 못했습니다. 교통 콘은 원뿔 모양의 표지물로, 일반적으로 도로나 보도에 배치되며 안전하고 일시적으로 교통을 우회시키거나 특정 구역을 차단하는 데 사용될 수 있습니다. 이들은 종종 도로 공사나 자동차 사고의 경우 교통 차선을 분리하거나 병합하는 데 사용될 수 있습니다. 이러한 상황들은 고해상도(HD) 지도로도 해결할 수 없기 때문에 차량 내 센서로 내부적으로 해결해야 합니다. 교통 콘은 임시적이고 이동 가능하기 때문입니다.\n이미지에서 직접 제어 출력(가속과 조향 명령)으로 매핑하는 엔드투엔드 접근 방식을 사용하고 싶을 수 있습니다[15]. 그러나 우리는 해석 가능한 하위 모듈을 가진 부분 기반 접근 방식과 데이터 주도 엔드투엔드 방법의 융합이 더 유망한 방향이라고 믿습니다. 어떤 경우에도 객체 감지는 자율주행 시스템 학습에 여전히 매우 필요합니다.\n여기서 흥미로운 점은 이러한 교통 콘들이 그 자체로는 정적 객체이지만, 도시 운전 시나리오에서 자주 교체되고 이동된다는 것입니다. 자동차는 예기치 않게 고장 날 수 있고 새로운 공사 구역이 예상보다 자주 생길 수 있습니다. 건물과 랜드마크는 쉽게 매핑하여 위치 확인에 사용할 수 있지만, 안전한 자동화 운전을 위해서는 이러한 교통 콘을 적극적으로 감지하고 위치를 추정해야 합니다.\nLiDAR와 같은 거리 기반 센서는 3D 위치를 정확하게 측정하도록 설계되었지만, LiDAR는 이미지에 비해 희소한 표현을 가지고 있어 작은 물체를 감지하고 색상과 질감과 같은 물리적 특성을 예측하는 것이 큰 과제가 됩니다. 또한, LiDAR 센서는 카메라보다 비용이 더 높아 이러한 플랫폼의 비용을 스펙트럼의 상위 끝으로 밀어 올립니다. 컴퓨터 비전의 발전은 단안 카메라의 이미지만으로도 장면에 무엇이 있는지 뿐만 아니라 3D 세계에서 물리적으로 어디에 있는지도 알 수 있음을 보여줍니다13, 14. 단안 카메라를 사용하는 또 다른 장점은 다중 카메라 설정이 필요하지 않아 시스템이 더 비용 효율적이고 유지 관리가 용이하다는 것입니다.\n이 연구에서 우리는 단일 이미지에서 교통 콘의 3D 위치 추정과 감지를 다룹니다. 우리는 이 작업을 세 단계로 나눕니다: 2D 객체 감지, 랜드마크 키포인트 회귀, 그리고 마지막으로 2D 이미지 공간에서 3D 세계 좌표로의 매핑입니다. 특히, 콘은 이 시나리오에 맞춤화된 기성 2D 객체 감지기에 의해 이미지에서 감지됩니다; 감지된 2D 경계 상자는 우리가 제안한 합성곱 신경망에 입력되어 교통 콘의 7개 랜드마크 키포인트를 회귀하며, 여기서 교차비(Cr)가 투영 불변이라는 사실이 견고성을 위해 활용됩니다. 마지막으로, 콘의 3D 위치는 원근 n-점 알고리즘에 의해 복구됩니다. 우리의 알고리즘을 훈련하고 평가하기 위해, 우리는 교통 콘을 위한 자체 데이터셋을 구축합니다.\n광범위한 실험을 통해 우리는 우리의 방법을 사용하여 단일 이미지로 교통 콘을 정확하게 감지할 수 있음을 보여줍니다. 3D 콘 위치 추정은 지상 진실과 비교했을 때 10m 거리에서 0.5m, 16m 거리에서 1m만큼 편차가 있습니다. 우리는 실물 크기의 자율 경주용 자동차 형태의 중요한 실시간 시스템에 우리의 방법을 배치함으로써 그 성능을 더욱 검증합니다. 이 자동차는 교통 콘으로 둘러싸인 트랙에서 최고 속도 54 km/h로 주행할 수 있습니다.\n이 논문의 주요 기여는 (1) 단일 이미지를 사용한 실시간 3D 교통 콘 감지를 위한 새로운 방법과 (2) 우리의 파이프라인의 정확도가 최고 속도 54 km/h로 경주용 자동차를 자율적으로 운행하기에 충분함을 보여주는 시스템입니다. 교통 콘으로 둘러싸인 트랙을 통과하는 우리 차량의 영상은 youtu.be/HegmIXASKow 에서 볼 수 있습니다.\n\nII. RELATED WORK\n빠른 객체 탐지. 객체 탐지는 컴퓨터 비전 분야에서 가장 중요한 문제 중 하나였습니다. 더욱이 로봇 플랫폼에서 특히 실시간, 온라인 성능을 위해서는 속도가 핵심입니다. 초기의 성공적인 빠른 객체 탐지기 중 하나는 Viola-Jones의 얼굴 탐지기15로, 약한 학습기를 사용하여 Haar 기반 특징을 이용해 정확하게 얼굴을 탐지합니다. 다음으로 잘 알려진 객체 탐지기 부류는 합성곱 신경망(CNN) 형태의 딥러닝을 사용합니다. R-CNN16, 17, 18 계열은 CNN 기반 특징을 영역 제안 분류에 사용합니다. YOLO19는 객체 탐지를 회귀 작업으로 교묘하게 공식화하여 매우 효율적인 탐지 시스템을 만들었습니다. 단일 샷 방식은 3D 객체 탐지에도 적용되었습니다20. 일반적인 객체 탐지 측면에서 진전이 있었지만, 교통 콘과 같은 소형 객체 클래스에 대한 성능은 추가 개선이 필요합니다.\n교통 장치 탐지. 교통 표지판9, 10과 신호등11, 12 탐지 방향으로 연구가 진행되었습니다. 벤치마킹 노력을 돕기 위해 100,000개의 주석이 달린 교통 표지판 이미지 데이터셋이 공개되었습니다21. Li 등22은 먼 거리의 교통 표지판과 같은 작은 객체 탐지를 개선하기 위해 생성적 적대 신경망(GAN)을 제안합니다. Lee 등23은 교통 표지판을 탐지하고 거친 사각형 형태의 경계 상자 대신 더 정교한 마스크를 출력하는 아이디어를 탐구합니다. 이 연구는 2개의 프레임에 걸쳐 추출된 객체 경계를 사용한 점들의 삼각측량에 대해 간단히 논의하지만, 시뮬레이션에만 국한되어 있습니다. 우리의 연구는 교통 콘 탐지와 단일 이미지만을 사용한 3D 위치 추정에 초점을 맞춥니다.\n키포인트 추정. 이 연구의 주요 기여 중 하나는 단일 프레임만으로 교통 콘의 3D 포즈를 정확하게 추정할 수 있다는 것입니다. 3D 기하학에 대한 사전 정보를 사용하여 키포인트라고 불리는 매우 특정한 특징점들을 회귀합니다. 이전에 포즈 추정과 키포인트는 다른 연구들24, 13에서 등장했습니다. Glasner 등13은 투표 SVM 앙상블을 사용하여 자동차가 포함된 이미지의 포즈를 추정합니다. Tulsiani 등14은 특징과 합성곱 신경망을 사용하여 다양한 객체의 시점을 예측합니다. 그들의 연구는 객체의 시점과 특정 객체에 대한 키포인트 간의 상호작용을 포착합니다. PoseCNN25은 딥러닝을 사용하여 6자유도 포즈를 직접 출력합니다. Gkioxari 등26은 k-부분 변형 가능한 부분 모델을 사용하여 사람에 대한 탐지와 키포인트 추출에 대한 통합된 접근 방식을 제시합니다. 우리의 방법은 교통 콘의 독특한 구조, 특히 교차비의 투영 불변 속성을 활용하여 강건한 키포인트 추정을 수행합니다.\n\nIII. MONOCULAR CAMERA PERCEPTION PIPELINE\nA. 센서 설정 및 계산 플랫폼\n실험 설정은 빠른 움직임으로 인한 이미지 왜곡과 아티팩트를 방지하기 위해 글로벌 셔터가 있는 2메가픽셀 카메라(CMOS 센서 기반)로 구성됩니다. 그림 2는 우리의 카메라 설정을 보여줍니다. 중앙 카메라는 이 연구에서 설명하는 단안 카메라로, 장거리 인식을 위해 12mm 렌즈를 사용합니다. 좌우 카메라는 5.5mm 초점 거리의 렌즈를 사용하며 가까운 콘을 삼각측량하는 스테레오 쌍으로 작동합니다. 카메라들은 맞춤 제작된 3D 프린팅 방수 쉘에 내장되어 있으며, 렌즈 앞에는 편광 필터가 있습니다. 카메라들은 공유 스위치를 통해 이더넷으로 데이터를 전송하여 깔끔한 카메라 하우징을 가능하게 합니다. 카메라들은 하단의 금속판에 나사로 고정되어 있으며, 작동 온도를 유지하기 위해 직접 접촉하고 있습니다. 원시 카메라 데이터는 “gotthard driverless” 온보드의 마스터 PIP-39(Intel i7 탑재)의 슬레이브 역할을 하는 Jetson TX2로 직접 전송됩니다. 이 파이프라인은 10Hz의 속도로 저전력 컴퓨팅에서 완전히 실행될 수 있을 만큼 가볍습니다.\nB. 파이프라인 개요\n단일 이미지에서의 포즈 추정은 잘 정의되지 않은 문제이지만, 관심 대상의 사전 구조 정보를 통해 해결할 수 있습니다. 방대한 양의 데이터와 GPU와 같은 강력한 하드웨어의 가용성으로, 딥 러닝은 고전적이고 수작업으로 만든 접근 방식으로는 해결하기 어려운 작업에 뛰어난 성능을 보여주었습니다. 데이터 기반 기계 학습은 정교한 표현을 학습하는 데 뛰어나며, 수학과 기하학에서 확립된 결과는 강건하고 신뢰할 수 있는 포즈 추정을 제공합니다. 우리의 연구에서는 파이프라인 접근 방식을 통해 성능과 해석 가능성을 모두 중요하게 여기면서 두 세계의 장점을 효율적으로 결합하고자 합니다.\n파이프라인의 하위 모듈들은 단일 이미지를 사용하여 관심 대상을 감지하고 그들의 3D 위치를 정확하게 추정할 수 있게 합니다. 파이프라인의 3가지 하위 모듈은 (1) 객체 감지, (2) 키포인트 회귀, (3) 2D-3D 대응을 통한 포즈 추정입니다. 파이프라인의 하위 모듈들은 Robot Operating System (ROS) 27 프레임워크를 사용하여 노드로 실행되며, 이는 파이프라인의 다른 부분들 사이와 다른 시스템 간의 데이터(메시지 형태) 통신과 전송을 처리합니다. 자세한 내용은 IV절에서 더 자세히 설명될 것입니다.\n\nIV. APPROACH\nA. 객체 탐지\n단일 이미지에서 여러 객체 인스턴스의 3D 위치를 추정하기 위해서는 먼저 이러한 관심 객체들을 탐지할 수 있어야 합니다. 객체 탐지 작업을 위해 우리는 파이프라인에 YOLOv228 형태의 기성 객체 탐지기를 사용합니다. YOLOv2는 Formula Student Driverless 이벤트(우리 플랫폼으로 참가한)에서 경주 트랙을 구분하는 주요 랜드마크 역할을 하는 다양한 색상의 콘을 탐지하도록 훈련되었습니다. 오탐지와 오분류를 최소화하기 위해 임계값과 매개변수들이 선택되었습니다. 이 특정 사용 사례에서 YOLOv2는 경주 트랙에서 특정 의미를 가진 노란색, 파란색, 주황색 콘만을 구별하면 되므로 탐지하는 클래스 수를 줄여 커스터마이즈되었습니다.\n콘의 경계 상자는 높이 대 너비 비율이 1보다 크기 때문에, 이러한 사전 정보를 활용하여 YOLOv2가 사용하는 앵커 박스를 재계산합니다(자세한 내용은28 참조).\n초기화에는 ImageNet29 챌린지를 위해 훈련된 가중치가 사용됩니다. 우리는 원래 연구 28와 유사한 훈련 방식을 따릅니다. 시즌 동안 더 많은 데이터가 수집되고 라벨링되면 탐지기는 미세 조정됩니다. 데이터 수집 및 주석에 대한 자세한 내용은 섹션 V-A.1을 참조하십시오.\nB. Keypoint Regression\n이 섹션에서는 단일 2D 이미지에서의 객체 탐지를 통해 관심 객체의 3D 위치를 추정하는 방법에 대해 논의합니다. 단일 뷰에서 이를 수행하는 것은 스케일로 인한 모호성 때문에 어렵습니다. 그러나 원뿔의 3D 형태, 크기 및 기하학에 대한 사전 정보를 통해 단일 이미지만으로도 탐지된 객체의 3D 포즈를 복원할 수 있습니다. 객체(3D)와 이미지(2D) 사이의 2D-3D 대응점 세트와 카메라의 내부 파라미터가 있다면 객체의 3D 포즈를 추정할 수 있습니다.\n이를 위해 우리는 고전적인 컴퓨터 비전에서 영감을 받았지만 기계 학습을 사용하여 데이터로부터 학습하는 특징 추출 방식을 소개합니다.\n\n키포인트 표현: 객체 탐지기의 경계 상자는 원뿔과 직접적으로 대응되지 않습니다. 이를 해결하기 위해 제안된 경계 상자 내에서 원뿔을 대표하는 랜드마크 특징을 추출합니다. 고전적인 컴퓨터 비전의 맥락에서 세 가지 종류의 특징이 있습니다: 평평한 영역, 엣지, 코너입니다. 엣지는 평평한 영역보다 더 흥미롭습니다. 왜냐하면 한 방향(엣지 경계에 수직인)으로 그래디언트가 있지만 조리개 문제30를 겪기 때문입니다. 가장 흥미로운 특징은 코너로, 한 방향이 아닌 두 방향으로 그래디언트가 있어 세 가지 중 가장 구별됩니다.\n\n이전의 특징 추출 작업에는 유명한 Harris 코너 검출기31, 강건한 SIFT32, SURF33 특징 추출기 및 기술자가 포함됩니다. 이들 중 많은 것들이 가지고 있는 속성은 스케일, 회전, 조명과 같은 변환에 대한 불변성으로, 대부분의 사용 사례에서 매우 바람직합니다. 이들 대부분은 일반적인 특징 검출기로 잘 작동하며 다양한 응용 분야에서 사용될 수 있습니다.\n기존의 특징 추출 기술을 사용하는 데 있어 문제점은 이들이 일반적이며 특징점의 기준에 부합하는 모든 종류의 특징을 검출한다는 것입니다. 예를 들어, Harris 코너는 특징점이 원뿔에 있는지 도로의 균열에 있는지 구별하지 않습니다. 이로 인해 관련된 2D 대응점을 추출하고 이를 3D 대응점과 정확히 매칭하기 어렵습니다. 또 다른 문제는 패치의 해상도가 낮을 때 몇 개의 특징만 검출될 수 있어 객체의 3D 포즈를 추정하기에 충분한 정보를 제공하지 못할 수 있다는 것입니다.\n\n키포인트 회귀: 이전에 제안된 작업의 이러한 한계를 염두에 두고, 우리는 이미지 패치가 주어졌을 때 “코너”와 같은 특징을 회귀하는 합성곱 신경망(CNN)을 설계합니다. 일반적인 특징 추출 기술에 비해 주요 장점은 데이터의 도움으로 매우 특정한 특징점을 강건하게 검출하는 법을 학습할 수 있다는 것입니다. 이 작업에서는 특정 객체 클래스인 원뿔에 초점을 맞추지만, 제안된 키포인트 회귀 방식은 다른 유형의 객체에도 쉽게 확장될 수 있습니다. 이러한 특정 특징점에 해당하는 3D 위치(그림 4에 표시된 대로)는 임의의 세계 좌표계 F_w에서 3D로 측정될 수 있습니다. 우리의 목적을 위해 이 좌표계를 원뿔의 밑면에 배치합니다.\n\n이러한 키포인트를 해당 위치에 배치하는 데에는 두 가지 이유가 있습니다. 첫째, 키포인트 네트워크는 시각적으로 구별되고 “코너” 특징과 시각적으로 유사하다고 간주될 수 있는 7개의 매우 특정한 특징의 위치를 회귀합니다. 둘째, 더 중요하게는 이 7개의 점은 고정된 세계 좌표계 F_w에서 3D로 상대적으로 쉽게 측정할 수 있습니다. 편의상 F_w는 3D 원뿔의 밑면으로 선택되어 이 세계 좌표계 F_w에서 이 7개 점의 3D 위치 측정을 가능하게 합니다. 7개의 키포인트는 원뿔의 꼭짓점, 원뿔 밑면의 양쪽에 있는 두 점, 중앙 줄무늬와 배경, 상/하부 줄무늬가 만나는 4개의 점입니다.\n특정 “코너” 특징을 검출하도록 맞춤 제작된 CNN은 객체 탐지기에 의해 검출된 원뿔을 포함하는 80×80×3 크기의 하위 이미지 패치를 입력으로 받아 \\mathbb{R}^{14}로 매핑합니다. 공간 차원은 80×80으로 선택되었는데, 이는 검출된 경계 상자의 평균 크기입니다. \\mathbb{R}^{14}의 출력 벡터는 키포인트의 (x,y) 좌표입니다.\n합성곱 신경망의 아키텍처는 ResNet34에서 영감을 받은 기본 잔차 블록으로 구성되며 PyTorch35 프레임워크를 사용하여 구현됩니다.\n36에서 분석된 바와 같이, 더 많은 합성곱 층을 사용하면 텐서 볼륨의 채널은 더 많아지지만 반면에 공간 차원이 크게 감소하여 텐서가 특정하고 지역적인 정보보다는 더 전역적이고 고수준의 정보를 포함하게 됩니다. 우리는 결국 키포인트의 위치에 관심이 있는데, 이는 매우 특정하고 지역적입니다. 이러한 아키텍처를 사용하면 키포인트의 위치를 정확하게 예측하는 데 중요한 공간 정보의 손실을 방지할 수 있습니다.\n네트워크의 백본은 ResNet과 유사합니다. 네트워크의 첫 번째 블록은 배치 정규화(BN)와 비선형 활성화 함수로 정류된 선형 유닛(ReLU)이 뒤따르는 합성곱 층입니다. 다음 4개의 블록은 그림 5에 묘사된 대로 채널 수가 증가하는 C \\in {64,128,256,512} 기본 잔차 블록입니다. 마지막으로 패치 내 키포인트의 (x,y) 위치를 회귀하는 완전 연결 층이 있습니다.\n\n손실 함수: 앞서 언급했듯이, 우리는 이미지(2D)의 키포인트와 물리적 원뿔(3D)의 위치 사이의 2D-3D 대응을 매칭하기 위해 객체 특정 사전 정보를 사용합니다. 또한 키포인트 네트워크는 교차비의 개념을 통해 손실 함수를 통해 객체의 3D 기하학과 외관에 대한 사전 정보를 활용합니다. 알려진 바와 같이, 투영 변환 하에서는 점 사이의 거리나 그 비율이 보존되지 않습니다. 그러나 거리의 비율의 비율인 더 복잡한 개체인 교차비는 불변이며 투영 하에서 보존됩니다. 기하학을 포함하는 고전적인 컴퓨터 비전 접근법에서 사용되었지만, 교차비는 기계 학습의 맥락에서는 거의 사용되지 않았습니다. 우리는 이를 사용하여 키포인트의 위치를 기하학적으로 제약하고 모델의 손실 함수에 직접 통합합니다.\n\n교차비(Cr)는 스칼라 양이며 4개의 공선 점 또는 5개 이상의 비공선 점으로 계산할 수 있습니다37. 이는 투영 하에서 불변이며 카메라로 이미지를 획득하는 과정은 본질적으로 투영 변환입니다. 교차비는 장면의 2D 투영(이미지)과 객체가 존재하는 3D 공간 모두에서 보존됩니다.\n우리의 경우, 4개의 공선 점 p_1, p_2, p_3, p_4를 사용하여 방정식 1에 정의된 대로 교차비를 계산합니다. 3D 점(D=3)인지 또는 그들의 투영된 2차원 대응점(D=2)인지에 따라 두 점 p_i와 p_j 사이의 거리 \\Delta_{ij}가 정의됩니다. \n\\tag{1}\n\\begin{align*}\nCr(p_1, p_2, p_3, p_4) = (\\Delta_{13}/\\Delta_{14})/(\\Delta_{23}/\\Delta_{24}) \\in R \\\\\n\\Delta_{ij}=\\sqrt{\\Sigma^D_{n=1}(X^{(n)}_i-X^{(n)}_j)^2}, D \\in {2,3}\n\\end{align*}\n\n정규화 역할을 하는 교차비 외에도, 손실 함수는 각 회귀된 키포인트의 (x,y) 위치에 대한 제곱 오차 항을 포함합니다. 제곱 오차 항은 회귀된 출력이 키포인트의 실제 주석에 최대한 가깝도록 강제합니다. 교차비의 효과는 인자 \\gamma에 의해 제어되며 0.0001의 값으로 설정됩니다. \n\\tag{2}\n\\begin{align*}\n\\Sigma^7_{i=1}(p^{(x)}_i-p^{(x)}_{i\\_groundtruth})^2+(p^{(y)}_i-p^{(y)}_{i\\_groundtruth})^2 \\\\\n+ \\gamma \\cdot (Cr(p_1, p_2, p_3, p_4)-Cr_{3D})^2 \\\\\n+ \\gamma \\cdot (Cr(p_1, p_5, p_6, p_7)-Cr_{3D})^2\n\\end{align*}\n\n두 번째와 세 번째 항은 3D에서 측정된 교차비(Cr_{3D})와 키포인트 회귀기의 출력을 기반으로 2D에서 계산된 교차비 사이의 오차를 최소화하여 간접적으로 CNN이 출력하는 위치에 영향을 미칩니다. 방정식 2의 두 번째 항은 원뿔의 왼쪽 팔을 나타내고 세 번째 항은 오른쪽 팔을 나타냅니다(그림 6 참조). 교차비에 대해, 우리는 이미 알려진 3D 추정치(Cr_{3D} = 1.39408, \\textsf{ 실제 원뿔에서})와 그 2D 대응치 사이의 제곱 오차 항을 최소화하기로 선택합니다. 방정식 2는 키포인트 회귀기를 훈련하는 동안 최소화되는 손실 함수를 나타냅니다. 훈련 방식은 다음 섹션에서 설명됩니다.\n\n훈련: 모델을 훈련시키기 위해 확률적 경사 하강법(SGD)이 최적화에 사용되며, 학습률 = 0.0001, 모멘텀 = 0.9, 배치 크기는 128입니다. 학습률은 75 및 100 에폭 후에 0.1배로 조정됩니다. 네트워크는 250 에폭 동안 훈련됩니다. 키포인트 회귀기는 PyTorch로 구현되어 “gotthard driverless”에서 ROS를 통해 사용됩니다. 데이터셋에 대한 자세한 정보는 섹션 V-A.2를 참조하십시오.\n\nC. 2D에서 3D로의 대응\n키포인트 네트워크는 관심 객체의 특정 특징, 즉 키포인트의 위치를 제공합니다. 우리는 관심 객체(이 경우 원뿔)의 형태, 크기, 외관 및 3D 기하학과 같은 사전 정보를 사용하여 2D-3D 대응 매칭을 수행합니다. 카메라의 내부 파라미터를 사용할 수 있고 키포인트 네트워크가 2D-3D 대응을 제공합니다. 이러한 정보를 사용하여 단일 이미지만으로도 해당 객체의 3D 포즈를 추정할 수 있습니다. 우리는 Perspective n-Point (PnP) 알고리즘을 사용하여 이러한 정보를 결합합니다.\n카메라 프레임을 F_c로, 세계 프레임을 F_w로 정의합니다. F_w는 임의로 선택될 수 있지만, 우리의 경우 키포인트의 3D 위치(F_w \\textsf{에 대해})를 쉽게 측정하고 변환을 계산하여 최종적으로 원뿔 위치를 편리하게 계산할 수 있도록 모든 검출된 원뿔의 밑면에 F_w를 선택합니다.\n우리는 Perspective n-Point를 사용하여 검출된 모든 원뿔의 포즈를 추정합니다. 이는 카메라 좌표계 F_c와 세계 좌표계 F_w 사이의 변환 ^cT_w를 추정함으로써 작동합니다. 우리는 F_c와 F_w 사이의 변환에만 관심이 있으며, 이는 우리가 추정하고자 하는 카메라 프레임에 대한 원뿔의 위치와 정확히 일치하므로, 우리의 경우 방향은 무시합니다.\n원뿔의 위치를 정확하게 추정하기 위해, 우리는 OpenCV38에 구현된 비선형 PnP를 사용하며, 이는 Levenberg-Marquardt를 사용하여 변환을 얻습니다. 또한, 노이즈가 있는 대응을 처리하기 위해 일반 PnP 대신 RANSAC PnP를 사용합니다. RANSAC PnP는 각 검출된 원뿔에 대한 2D-3D 대응 세트에 대해 수행됩니다. 즉, 패치를 키포인트 회귀기에 통과시켜 키포인트를 추출하고 미리 계산된 3D 대응을 사용하여 3D 위치를 추정합니다. 카메라 프레임과 자차 프레임 사이의 변환을 통해 각 원뿔의 자동차 프레임에서의 위치를 얻을 수 있습니다.\n\nV. DATA COLLECTION AND EXPERIMENTS\nA. 데이터셋 수집 및 주석\n제안된 파이프라인의 객체 탐지 및 키포인트 회귀를 위한 데이터를 훈련하고 평가하기 위해 데이터를 수집하고 수동으로 라벨링했습니다. 단일 이미지를 사용한 제안 방법의 위치 추정 정확도를 분석하기 위해 LiDAR의 도움을 받아 3D 실측 데이터를 수집했습니다.\n\n교통 콘 탐지: 객체 탐지기는 획득한 데이터셋의 90%(약 2,700개의 수동 주석 이미지)로 훈련되었으며, 성능은 데이터의 10%(약 300개의 미확인 이미지)로 평가되었습니다.\n콘 패치의 키포인트: 전체 이미지에서 900개의 콘 패치를 추출하여 자체 개발한 주석 도구를 사용하여 수동으로 라벨링했습니다. \n\n데이터 증강. 데이터셋은 20개의 무작위 변환을 통해 이미지를 변형하여 추가로 증강되었습니다. 이는 [-15\\degree,\\ +15\\degree] 사이의 무작위 회전, 0.8배에서 1.5배 사이의 크기 조정, 그리고 최대 50%의 모서리 길이 이동의 조합이었습니다. 훈련 과정 중에는 대비, 채도, 밝기 형태로 데이터가 실시간으로 추가 증강됩니다. 최종 증강된 주석 데이터셋은 16,000개의 콘 패치를 훈련용으로, 나머지 2,000개의 콘 패치를 테스트용으로 분할했습니다.\n\nLiDAR의 3D 실측 데이터: 3D 위치 추정의 정확도를 테스트하기 위해 LiDAR로 측정한 해당 객체 위치를 실측 데이터로 취급했습니다. 이는 4m에서 18m까지 다양한 거리에 있는 104개의 물리적 콘에 대해 수행되었습니다. 추정치는 그림 9에서 비교되며 섹션 V-D에 요약되어 있습니다.\n\n이 섹션에서는 단안 인식 파이프라인의 결과를 분석하고 논의하며, 특히 키포인트 네트워크의 견고성과 단일 이미지를 사용한 제안 방식의 3D 위치 추정 정확도에 주목합니다. 키포인트 네트워크는 Jetson TX2에서 파이프라인의 다른 하위 모듈을 실행하고 1 Gb/s의 원시 이미지 데이터를 처리하면서 0.06초 내에 단일 프레임에서 여러 콘 패치를 처리할 수 있어 초당 15-16 프레임으로 작동합니다.\nB. 콘 탐지\n표 II는 콘 탐지 하위 모듈의 성능 평가를 요약합니다. 시스템은 높은 재현율을 가지며 예상되는 대부분의 경계 상자를 검색할 수 있습니다. 높은 정밀도로 인해 오탐지에 대해 회피적이며, 이는 경주용 자동차를 트랙 한계 내에 유지하는 데 가장 중요합니다. 그림 3은 다양한 날씨와 조명 조건에서 콘 탐지 파이프라인의 견고성을 보여줍니다. 색상이 있는 콘 탐지는 각각의 색상으로 된 경계 상자로 표시됩니다. 자율 주행 차량을 성공적으로 운전하는 핵심은 오탐지가 최소화되거나 없는 인식 시스템을 설계하는 것입니다. 오탐지는 콘(장애물) 환각을 유발하여 차량을 코스 이탈로 이끌 수 있습니다. 콘 탐지 모듈은 약 18-20m 깊이까지 콘을 탐지할 수 있지만, 작은 크기로 인해 더 멀리 있는 콘에 대해 더 일관성 있게 작동합니다.\nC. 키포인트 회귀\n그림 7은 YOLOv2에 의해 탐지된 후 키포인트에 대해 회귀된 10개의 샘플 패치 몽타주를 보여줍니다. 상단 행의 왼쪽에서 두 번째 콘은 이미지의 오른쪽 가장자리에서 탐지되어 부분적으로만 보이며 검은색 픽셀로 패딩되었습니다. 픽셀이 누락되고 콘의 일부에 대한 정보가 없어도 제안된 회귀기는 키포인트를 예측합니다. 이는 기하학과 한 키포인트와 다른 키포인트 간의 상대적 위치를 학습합니다. 콘을 부분적으로만 관찰하더라도 완전한 이미지의 경우 키포인트가 어디에 있었을지 근사합니다. 예시를 통해 데이터를 통해 키포인트의 공간 배열과 기하학을 이해할 수 있음을 알 수 있습니다. 하단 행의 왼쪽에서 두 번째 콘의 경우 배경에 다른 콘이 있지만 키포인트 네트워크는 더 두드러진 콘으로 회귀할 수 있습니다. 경계 상자의 크기가 작아질수록 하위 이미지의 해상도가 낮아져 정확한 회귀가 더 어려워진다는 점에 주목해야 합니다. 이는 첫 번째 행의 마지막 두 콘 샘플에서 볼 수 있습니다.\n우리는 교차비 항을 평균 제곱 항에 추가한 식 2)의 손실을 사용하여 모델을 훈련합니다. 키포인트 회귀기의 성능은 평균 제곱 오차를 사용하여 평가합니다. 최종 키포인트 회귀 모델의 훈련 및 테스트 분할에 대한 성능은 표 III에 요약되어 있습니다. 예측과 실측 데이터 간의 평균 제곱 오차로 측정된 경험적 성능은 훈련과 테스트 분할 간에 매우 유사하여 네트워크가 콘 패치가 주어졌을 때 키포인트를 정확하게 지역화하는 방법을 학습했으며 과적합되지 않았음을 의미합니다.\n그림 7은 키포인트 회귀기의 견고성과 정확도를 보여주지만, 이는 키포인트 네트워크 하위 모듈의 내부 성능만을 나타냅니다. 다음 하위 섹션에서는 중간 하위 모듈의 출력이 3D 콘 위치에 어떤 영향을 미치는지 분석합니다. 또한 특정 하위 모듈의 출력 변동성이 파이프라인을 통해 어떻게 파급되어 최종 위치 추정에 영향을 미치는지 보여줍니다.\nD. 3D 위치 정확도\n실시간 자율 주행 자동차에 배포되므로 가장 중요한 측면 중 하나는 추정된 3D 위치의 정확도입니다. 우리는 파이프라인의 정확도를 실측 데이터로 취급되는 LiDAR의 3D 추정치와 비교합니다. 그림 9는 2개의 다른 테스트 트랙에서 얻은 데이터를 보여줍니다. x\\,축은 물리적 콘의 깊이(미터)를 나타내고, y\\,축은 LiDAR 추정치의 3D 위치와 단안 카메라 파이프라인의 3D 위치 간의 유클리드 거리를 나타냅니다. 이 그래프는 104개의 물리적 콘을 데이터 포인트로 포함합니다. 또한 데이터에 2차 곡선이 맞춰졌으며, 이는 대부분 선형 성분을 가집니다. 평균적으로 자아 차량에서 10m 떨어진 거리에서 차이는 약 0.5m이고 16m 거리에서는 약 1m입니다. 5m에서 콘 위치는 거리의 \\pm\\,5.00\\% 오차가 있고, 16m에서는 거리의 \\pm\\,6.25\\% 오차만 있습니다. 이 오차는 자율 주행 자동차가 50 km/h 이상의 속도로 콘으로 둘러싸인 트랙을 주행하기에 충분히 작습니다.\nE. 확장된 인식 범위\n이 방법의 목표 중 하나는 인식 범위를 확장하는 것입니다. 그림 10에서는 단안 및 스테레오 파이프라인의 범위 차이를 비교합니다. 단안 카메라를 사용한 우리의 제안 작업은 스테레오 카메라 기반의 표준 삼각측량 솔루션보다 더 큰 인식 범위를 가집니다. 또한 단안 카메라는 스테레오 카메라보다 더 긴 초점 거리를 가집니다. 스테레오 쌍도 더 긴 초점 거리를 가진다면 시야가 줄어들어 스테레오 카메라가 삼각측량할 수 없는 사각지대가 생깁니다.\nF. 2D 경계 상자가 3D 추정에 미치는 영향\n앞서 언급했듯이, 하위 모듈이 최종 3D 위치 추정에 어떤 영향을 미치는지 살펴보고자 합니다. 여기서는 한 단계 뒤로 물러나 객체 탐지 하위 모듈의 출력 변동성(부정확한 경계 상자)이 3D 위치에 어떤 영향을 미치는지 분석합니다. 이 실험에서는 경계 상자의 모서리를 각 방향의 높이와 너비에 비례하는 양만큼 무작위로 교란합니다. 센서의 본질적 특성으로 인해 카메라의 원시 데이터를 사용하여 깊이를 추정하는 것이 가장 어렵습니다. 그림 11은 단일 이미지에 대해 상자를 특정 양(\\pm\\,1\\%,\\ \\pm5\\%,\\ \\pm10\\% \\textsf{ 및 } \\pm20\\%)만큼 교란시키면 깊이 추정의 분산에 어떤 영향을 미치는지 보여줍니다. 예상대로 교란의 양이 클수록 깊이 추정의 분산이 더 크게 관찰됩니다. 그러나 \\pm\\,20\\% 교란에 대해서도 15m에서 분산은 약 1 m²입니다. 그림 11은 부정확하고 변동하는 경계 상자에도 불구하고 콘의 깊이가 일관되며 낮은 분산을 가짐을 보여줍니다.\n탐지, 회귀, 3D 위치 추정, 매핑 및 최종 내비게이션에 대한 추가 시각화는 프로젝트 페이지 people.ee.ethz.ch/˜tracezuerich/TrafficCone/를 방문하십시오.\n\nCONCLUSION\n정확하고 실시간으로 이루어지는 3D 포즈 추정은 증강 현실부터 자율 주행에 이르기까지 다양한 응용 분야에서 활용될 수 있습니다. 우리는 교차비(cross-ratio) 손실 항을 활용한 기하학적 형태를 통해 특정 특징점을 추출하는 새로운 키포인트 회귀 방식을 소개합니다. 이 접근 방식은 단안 카메라로부터 3D 포즈를 추정하고 객체의 구조적 사전 정보를 활용하여 다양한 객체로 확장될 수 있습니다. 우리는 네트워크가 키포인트의 공간적 배열을 학습하고 도전적인 상황에서도 강건한 회귀를 수행할 수 있는 능력을 보여줍니다. 제안된 파이프라인의 효과성과 정확성을 입증하기 위해 자율 주행 경주용 자동차에 배포되었습니다. 제안된 네트워크는 실시간으로 작동하며, 16m 거리에서 3D 위치 오차가 단 1m에 불과합니다. 감사의 말. AMZ Driverless의 지원에 감사드립니다. 이 연구는 또한 TRACE-Zurich 프로젝트를 통해 Toyota Motor Europe의 지원을 받았습니다.\n\nFootnotes\n\n\nC. Urmson, J. Anhalt, H. Bae, J. A. D. Bagnell, and et al. Autonomous driving in urban environments: Boss and the urban challenge. Journal of Field Robotics Special Issue on the 2007 DARPA Urban Challenge, Part I, 25(8):425–466, June2008. ↩\n\n\nJ. Levinson, J. Askeland, S. Thrun, and et al. Towards fully autonomous driving: Systems and algorithms. In IEEE Intelligent Vehicles Symposium (IV), 2011. ↩\n\n\nS. Hecker, D. Dai, and L. Van Gool. End-to-end learning of driving models with surround-view cameras and route planners. In European Conference on Computer Vision (ECCV), 2018. ↩\n\n\nS. Hecker, D. Dai, and L. Van Gool. Learning accurate, comfortable and human-like driving. In arXiv-1903.10995, 2019. ↩\n\n\nC. Sakaridis, D. Dai, and L. Van Gool. Semantic foggy scene understanding with synthetic data. International Journal of Computer Vision, 2018. ↩\n\n\nD. Dai and L. Van Gool. Dark model adaptation: Semantic image segmentation from daytime to nighttime. In IEEE International Conference on Intelligent Transportation Systems, 2018. ↩\n\n\nA. Valada, J. Vertens, A. Dhall, and W. Burgard. Adapnet: Adap-tive semantic segmentation in adverse environmental conditions. In Robotics and Automation (ICRA), 2017 IEEE International Conference on, pages 4644–4651. IEEE, 2017. ↩\n\n\nR. McAllister, Y. Gal, A. Kendall, M. Van Der Wilk, A. Shah, R. Cipolla, and A. Weller. Concrete problems for autonomous vehicle safety: Advantages of bayesian deep learning. In International Joint Conference on Artificial Intelligence, 2017. ↩\n\n\nA. Ruta, F. Porikli, S. Watanabe, and Y. Li. In-vehicle camera traffic sign detection and recognition. Machine Vision and Applications, 22(2):359–375, Mar 2011. ↩ ↩2\n\n\nM. Mathias, R. Timofte, R. Benenson, and L. V. Gool. Traffic sign recognition how far are we from the solution? In International Joint Conference on Neural Networks (IJCNN), 2013. ↩ ↩2\n\n\nM. B. Jensen, M. P. Philipsen, A. Mgelmose, T. B. Moeslund, and M. M. Trivedi. Vision for looking at traffic lights: Issues, survey, and perspectives. IEEE Transactions on Intelligent Transportation Systems, 17(7):1800–1815, 2016. ↩ ↩2\n\n\nA. Fregin, J. Mller, and K. Dietmayer. Three ways of using stereo vision for traffic light recognition. In IEEE Intelligent Vehicles Symposium (IV), 2017. ↩ ↩2\n\n\nD. Glasner, M. Galun, S. Alpert, R. Basri, and G. Shakhnarovich. aware object detection and continuous pose estimation. Image and Vision Computing, 30(12):923–933, 2012. ↩ ↩2 ↩3\n\n\nS. Tulsiani and J. Malik. Viewpoints and keypoints. CoRR, abs/1411.6067, 2014. ↩ ↩2\n\n\nP. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, volume 1, pages I–I. IEEE, 2001. ↩\n\n\nR. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 580–587, 2014. ↩\n\n\nS. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91–99, 2015. ↩\n\n\nR. Girshick. Fast r-cnn. In Proceedings of the IEEE international conference on computer vision, pages 1440–1448, 2015. ↩\n\n\nJ. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 779–788, 2016. ↩\n\n\nW. Kehl, F. Manhardt, F. Tombari, S. Ilic, and N. Navab. Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great again. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017. ↩\n\n\nZ. Zhu, D. Liang, S. Zhang, X. Huang, B. Li, and S. Hu. Traffic-sign detection and classification in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016. ↩\n\n\nJ. Li, X. Liang, Y. Wei, T. Xu, J. Feng, and S. Yan. Perceptual generative adversarial networks for small object detection. ↩\n\n\nW. Kehl, F. Manhardt, F. Tombari, S. Ilic, and N. Navab. Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great again. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017. ↩\n\n\nS. Savarese and L. Fei-Fei. 3d generic object categorization, localiza-tion and pose estimation. 2007. ↩\n\n\nY. Xiang, T. Schmidt, V. Narayanan, and D. Fox. Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes. CoRR, abs/1711.00199, 2017. ↩\n\n\nG. Gkioxari, B. Hariharan, R. Girshick, and J. Malik. Using k-poselets for detecting people and localizing their keypoints. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3582–3589, 2014. ↩\n\n\nROS: Robot Operating System. ros.org/. ↩\n\n\nJ. Redmon and A. Farhadi. YOLO9000: better, faster, stronger. CoRR, abs/1612.08242, 2016. ↩ ↩2 ↩3\n\n\nJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248–255. Ieee, 2009. ↩\n\n\nR. Szeliski. Computer vision: algorithms and applications. Springer Science &amp; Business Media, 2010. ↩\n\n\nC. Harris and M. Stephens. A combined corner and edge detector. Citeseer, 1988. ↩\n\n\nD. G. Lowe. Distinctive image features from scale-invariant keypoints. International journal of computer vision, 60(2):91–110, 2004. ↩\n\n\nH. Bay, T. Tuytelaars, and L. Van Gool. Surf: Speeded up robust features. In European conference on computer vision, pages 404–417. Springer, 2006. ↩\n\n\nK. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016. ↩\n\n\nPyTorch. pytorch.org/. ↩\n\n\nO. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. CoRR, abs/1505.04597, 2015. ↩\n\n\nCross ratio. robotics.stanford.edu/˜birch/projective/node10.html. ↩\n\n\nOpenCV calibration and 3d reconstruction. docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#solvepnp. ↩\n\n\n"},"Web/API-Type":{"title":"API Type","links":[],"tags":["Web","API"],"content":"API Type\n각 API 는 다음을 정의\n\nProtocol : Control structure\nFormat : Content structure\n\nAPI 종류\n\n  \n  초기 API\n    \n      주로 Local Libaray Function 호출 형태\n    \n  \n  \n  \n  원격 프로시저 호출(RPC)\n    \n      다른 Process 나 Computer 의 Function 를 Local Function 처럼 호출\n      Ex) gRPC1\n    \n  \n  \n  \n  Messaging(RPC)\n    \n      Process 간 Small data Chunk2\n      Command 나 Event 가능\n      Ex) Apache Kafka3, RabbitMQ4, NATS5, ZeroMQ6\n    \n  \n  \n  \n  Communication Pattern(RPC)\n    \n      Request - Response : Web Browser - Web Server\n      Publish - Subscribe(Pub - Sub) : Publisher 가 Message publish, Subscriber 가 선별적으로 Receive\n      Queue : Pub - Sub 와 유사하나 Single Subscriber 만 Message Processing\n    \n  \n\n이 모든 기술들은 Web Service 에서도 Back-end Task 수행 등에 활용 가능\n\nFootnotes\n\n  Piece, Data 를 더 작은 단위로 나눈 것\n    ↩\n  \n"},"Web/Concurrency":{"title":"Concurrency","links":["Web/HTTP"],"tags":["Web"],"content":"Concurrency\n\n  Service 가 성장 시 효율성과 확장성이 중요, Latency1 &amp; Throughput2 개선 필요\n  완전한 Parallel Processing 이 아니라 Busy Waiting3 을 피하는 걸 의미\n\nAsynchronous Processing\n\n  Python 은 기본적으론 Synchronous4 이지만,   Asynchronous5 Processing 도 가능\n  I/O-bound6 Task 에 특히 유용\n  FastAPI 에 Synchronous Processing 을 적용하면 Performance 가 크게 향상\n  CPU 집약적 Task 를 과도하게 수행하지 않도록 주의7\n\nConcurrency 은 Modern Web Service 에서 중요한 개념이며, 적절히 활용하면 Performance 를 크게 개선 가능\n\nFootnotes\n\n  사전 idle time\n    ↩\n  \n  \n  Service 와 Caller 간의 초당 Byte 수\n    ↩\n  \n  \n  Process 나 Thread 가 특정 조건이 충족될 때까지 Idle State 로 대기하는 대신,    계속해서 해당 조건을 확인하는 Task 를 반복하는 것   CPU 자원을 소모하면서 대기하기에 비효율적일 순 있으나, Fast Response 가 필요한 상황에서 사용되기도 함\n    ↩\n  \n  \n  동기식 : Task 가 순차적으로 진행되며, 하나의 Task 가 완료될 때까지 Next Task 가 수행되지 않는 방식\n    ↩\n  \n  \n  비동기식 : Task 가 시작된 후 완료될 때 까지 기다리지 않고, Other Task 를 병행하여 수행할 수 있는 방식\n    ↩\n  \n  \n  Program 이나 Task 가 주로 I/O 에 의해 제한 되는 상태\n    \n      Disk Read/Write, Network Communication, File I/O, etc 에 많은 시간 소요\n      CPU 보다 I/O Task의 속도가 전체 성능을 좌우\n    \n  \n"},"Web/Data":{"title":"Data","links":[],"tags":["Web"],"content":"Data\n\n\nData Storage &amp; Access Method 의 진화\n\nNoSQL, NewSQL1 등 새로운 Database 기술 등장\nWeb 은 여전히 Relational Database 의 Front-end 역할 \n\n\n\n머신러닝의 영향\n\nDatabase 를 넘어 Machine Learning 이 Technical Environment 을 재편\n대규모 모델 개발에 ETL2 Task 필요성 증가 \n\n\n\nWeb 의 역할\n\nGeneral Service Architecture 로서 Machine Learning System 의 문제 해결에 기여 가능\n\n\n\nFootnotes\n\n\n전통 Database의 ACID 속성과 NoSQL의 확장성 제공을 시동하는 관계형 Database ↩\n\n\n추출, 변환 저장 ↩\n\n\n"},"Web/GraphQL":{"title":"GraphQL","links":["Web/REST","Web/Service--and--API"],"tags":["Web"],"content":"GraphQL\nRESTful API 의 한계\n\n특정 상황에서 사용하기 번거로울 수 있음\n\nGraphQL\n\nFacebook 이 개발한 더 유연한 Query Laungage\n현재로서는 사용할 계획 X\n나중에 여러대의 서버 혹은 확대할 시 적합하지 않다고 생각되면 검토 예정\n"},"Web/HTTP":{"title":"HTTP","links":["Web/Web"],"tags":["Web/HTTP"],"content":"HTTP\nTim Berners-Lee 가 제한한 WWW(World-Wide-Web)의 3가지 핵심 구성요소\n\nHTML : Data Display Language\nHTTP : Client - Server Protocol\nURL : Web Resource Addressing Schema\n\n이 세 가지 요소의 조합은 처음에는 단순해 보였지만, 시간이 지나면서 매우 강력하고 유용한 것으로 입증\nWeb 이 발전하면서 다양한 실험과 혁신(Ex: IMG 태그)이 이루어졌고, 이는 Web 의 필수적인 부분\n이러한 발전 과정에서 웹 표준의 중요성이 부각되어 더욱 체계적인 정의가 이루어지게 됨."},"Web/JSON--and--API-Data-Type":{"title":"JSON & API Data Type","links":["Web/Web"],"tags":["Web","API"],"content":"JSON &amp; API Data Type\nJSON(JavaScript Object Notation)\n\nFront-End &amp; Back-End 간 Data 교환을 위한 Text 기반 Format\nList 나 복잡한 Data Structure 를 표현하는 데 적합\n구문은 JavaScript 에서 유래했지만 Python 의 Directory 와 매우 유사\nXML 이나 SOAP 같은 이전의 Data Representation 을 대부분 대체\nModern Web Service 의 I/O Format 으로 널리 사용 중\n간단하고 효율적인 Data Representation 으로,   Modern Web Development 에서 중요한 역할\n"},"Web/JSON-API":{"title":"JSON:API","links":["Web/REST"],"tags":["Web","API"],"content":"JSON:API\nRESTful Design &amp; JSON Data Format\n\n조합이 일반화되었지만, 여전히 모호한 부분과 논쟁의 여지가 있음\nJSON:API1는 이러한 문제를 해결하기 위해 더 엄격한 사양 제안\n현재로서는 느슨한 RESTful 방식 사용\n추후 문제 및 논란이 발생할 경우 JSON:API 또는 이와 유사한 엄격한 방식 사용할 예정\n"},"Web/Layer":{"title":"Layer","links":["Web/HTTP","Web/Web","Web/API-Type","Web/JSON--and--API-Data-Type"],"tags":["Web"],"content":"Layer\nThree-Tier Model\n\nApplication 의 Size 와 복잡성을 관리하기 위해 널리 사용됨\nTerm 은 다양하게 사용되고 있으므로 이름이 다르다고 새로운 개념이 아니며 오랫동안 사용되어 온 방식\n\nTerm\n\nWeb : Client 의 Request 를 수집하고, Service Layer 을 Call 해 Response 하는 HTTP 를 통한 I/O Layer\nService : 필요할 때 Data Layer 를 Call 하는 Business Logic\nData : Data Storage &amp; Other Service 에 접근\nModel : All Layer 가 Share 하는 Data Definition\nWeb Client : Web Browser 또는 Other HTTP Client-Side Software\nDatabase : Data Storage(주로 SQL &amp; NoSQL Server)\n\n\n\n\nArchitecture\n\nWeb Layer : Client Request Processing &amp; HTTP I/O 담당\nService Layer : Business Logic Processing\nData Layer : Data 저장 및 접근\nModel Layer : All Layer 가 Share 하는 Data Definition\n\nLayer 분리의 이점\n\n전문성 분리\nTest 격리성\n기능 대체 및 보완 용이\n\n\n\n\nLayer 간 Communication\n\n  API 를 통해 이루어짐\n  각 Layer 간 권장 Data Format 존재\n    \n      Web Client ⇔ Web : JSON 을 사용한 RESTful HTTP\n      Web ⇔ Service : Model\n      Service ⇔ Data : Model\n      Data ⇔ Database &amp; Service : 특정 API\n    \n  \n\nDesign Principles\n\nModualarity : System 을 독립적인 Modual 로 나누어 Design 하여 유지보수와 이해 용이\nSingle Response : 각 Modual &amp; Component 를 가지도록 Design 해 복잡성 감소\nOpen/Closed : Software Modual 이 확장에는 열림, 수정에는 닫힘\nReusability : Design 한 Component &amp; Modual 이 Other System &amp; Project 에 재사용\nCoupling &amp; Cohesion : Coupling 감소, Cohesion 증가시켜   각 Modual 간 상호 의존을 줄이고, 각 Modual 기능을 명확히 할 것\nSimplicity : 가능한 Simple 하게 Design 하여 복잡성 감소, 이해와 유지보수 용이\nScalability : System 이 확장되거나 요구 사항이 변경될 때 Simple 하게 확장할 수 있게 Design\n\nCaution\n\nLayer 는 별도의 Program Language Modual 에 대한 간단한 Function 일 수 있으나,  어떤 방법 동원 시 External Code 에 접근할 여지가 충분\nLayer 혼합 시 분리 어려움\nLayer 라 부른다고 위 &amp; 아래 에 위치하고, Command 가 내려가는 것이 아님\nSpaghetti Code 는 Test 와 이해의 어려움 증가\n"},"Web/Pagination":{"title":"Pagination","links":[],"tags":["Web"],"content":"Pagination\n\nContent 를 여러 Page 로 나누어 다음 또느 이전 Page 로 이동  or  특정 Page 로 이동할 수 있는 요소\n"},"Web/REST":{"title":"REST(ful)","links":["Web/HTTP","Web/API-Type"],"tags":["Web"],"content":"REST(ful)\nREST(Representational State Transfer)의 주요 특징\n\n  HTTP Protocol Usage\n  상태 비저장(Stateless)1\n  Cacheable2\n  Resource3-based4\n\nRESTful Web Service 의 핵심 개념\n\nResource : Task 를 수행할 수 있는 Data\nEndpoint : 고유한 URL 과 HTTP 동사(동작)로 구성된 기능 접근\n\nHTTP 동사와 CRUD Task 의 대응\n\nPOST : 생성(Create)4\nGET : 읽기(Read)\nPATCH/PUT : 전체/부분 수정(Update)\nDELETE : 삭제(Delete)\n\nRESTful Communication\n\nRequest : Client 가 Data 를 Header , URL, Quary parameter, 본문에 담아 전송\nResponse : Server 가 State Code, Header, 본문으로 응답\n\nHTTP Status Code\n\n1xx : Information\n2xx : Success\n3xx : Redirection\n4xx : Client Error\n5xx : Server Error\n\nPS) 418 Status Code(I’m a teapot)는 Web 의 유머러스한 Easter Egg\n\n\nFootnotes\n\n  Server 가 Client 의 이전 Request 를 저장하지 않는 Architecture\n    ↩\n  \n  \n  Data 를 Cache 에 저장할 수 있는 지 여부\n    \n      (Server 로 부터 Re-request 하지 않고 Client Cache 에서 가져올 수 있는 Data)\n        ↩\n      \n    \n  \n  \n  Resource : User 가 식별하고 Task 를 수행할 수 있는 Data\n    ↩\n  \n  \n  Resource-based : 특정 System 이나 설계가 Resource 를 중심으로 작동하거나 조작되는 방식\n    ↩\n  \n  \n  Database 의 기본 동작\n    \n      쓰기(Create)\n      읽기(Read)\n      수정(Update)\n      삭제(Delete)\n    \n  \n"},"Web/Service--and--API":{"title":"Service & API","links":["Web/API-Type","Web/HTTP","Web/REST","Web/JSON--and--API-Data-Type","Web/JSON-API","Web/GraphQL"],"tags":["Web","API"],"content":"Web Service &amp; API\n\n  \n    API1 의 중요성\n      \n        Front-end &amp; Back-end 간 Communication 수단\n        Modern Web 에서 API design 의 중요성이 Website Design 만큼 중요\n      \n  \n  \n  \n    API 의 역할\n      \n        Database Schema2 와 유사한 규약 역할\n        API 정의와 수정, 중차대한 Task\n      \n  \n\nSubtitle\n\nAPI-Type\nHTTP\nREST(ful)\nJSON-&amp;-API-Data-Type\nJSON:API\nGraphQL\n\n\nFootnotes\n\n  Application Programming Interface\n    ↩\n  \n  Database System 에서 Structure, 구성 및 관계를 정의\n    ↩\n  \n"},"Web/Web":{"title":"Modern Web","links":[],"tags":["Web"],"content":"Web 의 역할 변화\n\n전통적으로는 Content 중심이었으나, 현재는 API1를 통한 연결성이 중요\n\nWeb 개발의 분화\n\nFront-end : UI2 제공(JS, Mobile App, etc)\nBack-end : Database 접근과 Business Logic3 Processing\n\nFootnotes\n\n\nApplication programming Interface ↩\n\n\nUser Interface ↩\n\n\nProgram 의 핵심 Logic(어떻게 Data 가 생성되고 저장되고 수정되는지를 정의) ↩\n\n\n"},"index":{"title":"Welcome to KMU-FMCL Docs","links":["Linux/Ubuntu","Language/C/C","Language/C++/C++","Language/Python/Python","Language/Rust/Rust","Language/Go/Go","Linux/Docker/Docker","ROS/ROS-2","Web/Web","Web/Service--and--API","Web/Concurrency","Web/Layer","Web/Data","Project/API-Server","Project/2024-Capstone-II","Reference/Real-time-3D-Traffic-Cone-Detection-for-Autonomous-Driving"],"tags":[],"content":"OS\n\nUbuntu\n\nProgram Language\n\nC\nC++\nPython\nRust\nGo\n\nSoftware\n\nDocker\nROS-2\n\nWeb\n\nService-&amp;-API\nConcurrency\nLayer\nData\n\nProject\n\nAPI-Server\n2024 스케일카 자율주행 경진대회\n\nReference\n\nReal-time 3D Traffic Cone Detection for Autonomous Driving\n\nSee the documentation for how to get started."}}